- _ulid: 01KH4DWQ6BNTGB4PE6PXKS1K24
  slugs:
    - port-design-doc
  title: Port design doc into kspec specs and tasks
  type: task
  description: Translate the ComfyUI node pack design document
    (~/Projects/merge-router/docs/comfyui-node-pack-design.md) into kspec spec items (modules,
    features, requirements with acceptance criteria) and derive implementation tasks. This should be
    done as a design session with review checkpoints — not all at once.
  spec_ref: null
  meta_ref: null
  plan_ref: null
  status: completed
  blocked_by: []
  closed_reason: null
  depends_on: []
  context: []
  priority: 1
  tags:
    - setup
    - design
  vcs_refs: []
  created_at: 2026-02-10T18:44:18.251Z
  started_at: 2026-02-10T19:47:05.721Z
  completed_at: 2026-02-10T21:40:56.673Z
  notes:
    - _ulid: 01KH4DZDER1NSMEDTPRYEWBNDB
      created_at: 2026-02-10T18:45:46.584Z
      author: "@claude"
      content: "Source document: ~/Projects/merge-router/docs/comfyui-node-pack-design.md (627+ lines, 8
        sections). Sections 6.8 (Exit Node Algorithm), 6.9 (Memory Strategy), and 6.10 (Per-Block
        Control) were written this session — they are complete but newer than the rest of the doc."
      supersedes: null
    - _ulid: 01KH4DZTRTJSRZ7CT7QCZT534V
      created_at: 2026-02-10T18:46:00.218Z
      author: "@claude"
      content: "Key design decisions already resolved (in §6.7 and §6.10): (1) Auto-detect architecture at
        Entry time from state dict keys. (2) Explicit backbone input on Merge node, defaults to
        base. (3) LoRA file selection via folder_paths.get_filename_list standard dropdown. (4) Exit
        node produces MODEL, saved via built-in ComfyUI save nodes. (5) Per-block control uses
        Option B — explicit BLOCK_CONFIG type wired into Merge (block_t_factor) and LoRA
        (block_strength) inputs. (6) One generic Block Config node per architecture (not two),
        semantics carried by input names on consumers. (7) Deferred execution — recipe nodes do zero
        GPU work, Exit runs full batched pipeline."
      supersedes: null
    - _ulid: 01KH4E058E4DY6405MKGBJHW08
      created_at: 2026-02-10T18:46:10.959Z
      author: "@claude"
      content: "Suggested module structure for specs: (1) nodes module — Entry, LoRA, Compose, Merge, Exit
        node specs with ACs for each. (2) core-algorithm module — WIDEN, divergence, ranking,
        numerical config (ported from merge-router). (3) executor module — batched pipeline,
        OpSignature grouping, GPU LoRA apply, OOM backoff. (4) lora-loading module —
        architecture-specific loaders (SDXL, Z-Image, Qwen), key mapping, QKV fusing. (5)
        block-config module — per-block control, architecture-specific Block Config nodes,
        BLOCK_CONFIG type."
      supersedes: null
    - _ulid: 01KH4E0DSSVM3M9YBBYY5G1207
      created_at: 2026-02-10T18:46:19.705Z
      author: "@claude"
      content: "User preference: this should be done as a design session with review checkpoints — present
        spec decomposition incrementally for approval, not all at once. Use /spec-plan workflow.
        Stub node files and recipe dataclasses already exist in the project (nodes/*.py,
        lib/recipe.py) which can inform AC writing."
      supersedes: null
    - _ulid: 01KH4E0P5Q1HW5AYXSWE0EQPWH
      created_at: 2026-02-10T18:46:28.279Z
      author: "@claude"
      content: "What NOT to port as specs: merge.py JSON config runner, CLI argument parsing, safetensors
        save logic, training infrastructure, Nu scripts. These are replaced by the ComfyUI node
        graph. The design doc §5 has the full port/no-port list."
      supersedes: null
    - _ulid: 01KH4E5KFNP2RN8144NKCXXWTM
      created_at: 2026-02-10T18:49:09.366Z
      author: "@claude"
      content: Design doc moved to docs/design.md in this project (copied from
        ~/Projects/merge-router/docs/comfyui-node-pack-design.md). References to merge-router source
        files now use full paths. Project structure section updated to comfy-ecaj-nodes/.
      supersedes: null
  todos: []
- _ulid: 01KH4H1VQFJC261BXN6377A7XS
  slugs:
    - implement-comfyui-packaging
  title: Implement ComfyUI Packaging
  type: task
  spec_ref: "@comfyui-packaging"
  plan_ref: "@plan-foundation-project-infrastructure"
  status: completed
  blocked_by: []
  closed_reason: "Merged in PR #1. Implemented ComfyUI packaging infrastructure: NODE_CLASS_MAPPINGS
    with 5 WIDEN nodes, pyproject.toml with [tool.comfy] metadata (PublisherId=ecaj,
    DisplayName=ECAJ Nodes), lowercase ecaj/merge CATEGORY on all nodes, empty runtime deps with dev
    deps in optional-dependencies. All 4 ACs covered by tests in test_packaging.py."
  depends_on: []
  context: []
  priority: 1
  tags: []
  vcs_refs: []
  created_at: 2026-02-10T19:39:32.463Z
  started_at: 2026-02-11T01:44:24.977Z
  completed_at: 2026-02-11T02:25:41.782Z
  notes:
    - _ulid: 01KH4H1VQF30CM22CSZ4A997WD
      created_at: 2026-02-10T19:39:32.463Z
      author: "@claude"
      content: |
        Implementation notes:

        Skeleton exists in __init__.py (5 WIDEN mappings) and pyproject.toml.
        Validate NODE_CLASS_MAPPINGS pattern works with ComfyUI node discovery.
        CATEGORY must use lowercase ecaj/ prefix with sub-categories per capability
        area (e.g., ecaj/merge for WIDEN nodes). Existing stubs use ECAJ/merge --
        update all to lowercase ecaj/merge. For the task: review ComfyUI's
        nodes_core.py loading path, verify pyproject.toml [tool.comfy] fields match
        registry requirements (PublisherId, DisplayName, Icon), ensure requirements.txt
        lists only dependencies ComfyUI doesn't already provide (torch and safetensors
        are provided by ComfyUI -- check if we need them at all), update CATEGORY on
        all 5 existing node stubs from ECAJ/merge to ecaj/merge.
        Files: __init__.py, pyproject.toml, requirements.txt, nodes/entry.py,
        nodes/lora.py, nodes/compose.py, nodes/merge.py, nodes/exit.py.
    - _ulid: 01KH55Y8QK84TTHF6Y531RSKMR
      created_at: 2026-02-11T01:44:34.803Z
      author: "@claude"
      content: "Fixed CATEGORY casing ECAJ/merge -> ecaj/merge in all 5 node stubs. Updated
        pyproject.toml: empty runtime deps, dev deps (pytest/ruff/torch), pytest config with
        importlib mode, ruff config (line-length=99, py310, isort+pyflakes+pyupgrade). Made
        requirements.txt comment-only. Added setuptools package discovery for flat layout. Made
        __init__.py safe to import outside ComfyUI (try/except for relative imports). Added root
        conftest.py with collect_ignore."
      supersedes: null
  todos: []
  automation: eligible
- _ulid: 01KH4H1VQK0HMMA7NP2BTSFZEA
  slugs:
    - implement-testing-infrastructure
  title: Implement Testing Infrastructure
  type: task
  spec_ref: "@testing-infrastructure"
  plan_ref: "@plan-foundation-project-infrastructure"
  status: completed
  blocked_by: []
  closed_reason: "Merged in PR #1. Implemented testing infrastructure with: MockModelPatcher (4x4
    float32 tensors, SDXL-like keys,
    model_state_dict/clone/add_patches/get_key_patches/patches_uuid), recipe fixtures (recipe_base,
    recipe_single_lora, recipe_multi_lora, recipe_compose, recipe_chain), autouse ComfyUI API mocks
    (folder_paths, comfy modules). All 37 tests pass without ComfyUI. All 4 ACs verified with test
    coverage."
  depends_on: []
  context: []
  priority: 1
  tags: []
  vcs_refs: []
  created_at: 2026-02-10T19:39:32.467Z
  started_at: 2026-02-11T01:44:45.085Z
  completed_at: 2026-02-11T02:26:48.995Z
  notes:
    - _ulid: 01KH4H1VQK71QYFPXSF52PYAVJ
      created_at: 2026-02-10T19:39:32.467Z
      author: "@claude"
      content: |
        Implementation notes:

        Create tests/conftest.py with: (1) MockModelPatcher class -- needs
        model_state_dict(filter_prefix) returning a dict of fake tensors keyed like
        diffusion_model.input_blocks.0.0.weight, clone() returning a new
        MockModelPatcher, add_patches(patches, strength_patch, strength_model)
        storing patches, get_key_patches(filter_prefix) returning patch data,
        patches_uuid property. Use small tensors (e.g., 4x4 float32) for speed.
        (2) Recipe tree fixtures -- recipe_base() returning RecipeBase with
        MockModelPatcher and arch=sdxl, recipe_single_lora(), recipe_lora_set()
        (2 LoRAs chained), recipe_compose() (2 branches), recipe_chain() (2
        sequential merges), recipe_full() (compose + chain like hyphoria example
        from design doc section 6.5). (3) Mock folder_paths module --
        get_filename_list(loras) returning [test.safetensors]. (4) pytest config
        in pyproject.toml [tool.pytest.ini_options] with testpaths=[tests].
        Files: tests/conftest.py, pyproject.toml (pytest config section).
    - _ulid: 01KH54VWW1HZ2WMCP921EZKDSD
      created_at: 2026-02-11T01:25:48.545Z
      author: "@claude"
      content: "Dependencies cleared (was: @implement-comfyui-mocking-and-fixtures,
        @implement-node-graph-testing, @implement-ci-pipeline)"
      supersedes: null
    - _ulid: 01KH55YYAYCTEQ1X0ZX0RZQP3G
      created_at: 2026-02-11T01:44:56.926Z
      author: "@claude"
      content: "Created tests/conftest.py with: MockModelPatcher (4x4 float32 tensors, SDXL-like keys,
        model_state_dict/clone/add_patches/get_key_patches/patches_uuid), recipe fixtures
        (mock_model_patcher, recipe_base, recipe_single_lora, recipe_multi_lora, recipe_compose,
        recipe_chain), autouse ComfyUI API mocks (folder_paths, comfy, comfy.utils,
        comfy.model_management). Created 3 test files: test_packaging.py (5 smoke tests for node
        attributes/CATEGORY), test_recipe.py (13 tests for frozen/tuple/structure),
        test_mock_model_patcher.py (15 tests for mock fidelity). All 33 tests pass without ComfyUI,
        ruff clean."
      supersedes: null
  todos: []
  automation: eligible
- _ulid: 01KH4HA460E5KKNBG2WJJK17GX
  slugs:
    - implement-recipe-type-system
  title: Implement Recipe Type System
  type: task
  spec_ref: "@recipe-system"
  plan_ref: "@plan-widen-merge-feature-specs"
  status: completed
  blocked_by: []
  closed_reason: "Merged in PR #3. Implemented recipe type system with frozen dataclasses, tuple
    fields, RecipeCompose.with_branch() for persistent tree semantics, RecipeNode type alias, and
    __all__ exports. All 5 ACs have test coverage: AC-1 (frozen), AC-2 (persistent semantics), AC-3
    (no GPU tensors), AC-4 (importable/constructible), AC-5 (WIDEN wire connections)."
  depends_on: []
  context: []
  priority: 1
  tags: []
  vcs_refs: []
  created_at: 2026-02-10T19:44:03.264Z
  started_at: 2026-02-11T02:28:43.363Z
  completed_at: 2026-02-11T02:32:59.881Z
  notes:
    - _ulid: 01KH4HA46066MMF0GVC5BDX526
      created_at: 2026-02-10T19:44:03.264Z
      author: "@claude"
      content: |
        Implementation notes:

        Partially implemented in lib/recipe.py -- has all 4 dataclasses but
        missing BlockConfig (added later in per-block-control). The WIDEN custom
        type is registered implicitly by ComfyUI when a node declares
        RETURN_TYPES = ("WIDEN",) -- no explicit registration needed, but verify
        this works by checking that ComfyUI type system allows connections between
        nodes sharing the custom type name. AC-5 can be tested by constructing a
        mock workflow JSON with WIDEN connections and validating against ComfyUI
        graph validation, or by testing in a running ComfyUI instance. For the
        task: verify existing dataclasses match design doc section 6.6, ensure all
        fields use tuples (not lists), verify frozen=True on all, add __all__
        export list. Consider adding RecipeNode = Union[RecipeBase, RecipeLoRA,
        RecipeCompose, RecipeMerge] type alias for type checking.
        Files: lib/recipe.py.
    - _ulid: 01KH58K0JPCQZHDM7Z3ZB6P5M0
      created_at: 2026-02-11T02:30:51.734Z
      author: "@claude"
      content: "Completed Recipe Type System: added RecipeCompose.with_branch() for persistent tree
        semantics (AC-2), added RecipeNode type alias, added __all__ exports. Added 18 new tests: 4
        for AC-2 (with_branch returns new instance, original unchanged), 4 for AC-3 (no GPU tensors
        in recipe objects), 3 for AC-4 (all classes importable/constructible), 7 for AC-5 (WIDEN
        wire connections between nodes). All 58 tests pass, ruff clean."
      supersedes: null
  todos: []
  automation: eligible
- _ulid: 01KH4HA463BT1D6RF0ZD1DRW2P
  slugs:
    - implement-entry-node
  title: Implement Entry Node
  type: task
  spec_ref: "@entry-node"
  plan_ref: "@plan-widen-merge-feature-specs"
  status: completed
  blocked_by: []
  closed_reason: "Merged in PR #5. Implemented WIDEN Entry Node with architecture detection (SDXL,
    Z-Image supported; Flux/Qwen detected but unsupported). All 5 ACs covered by 17 tests. No GPU
    memory allocation or tensor copying."
  depends_on:
    - "@implement-testing-infrastructure"
    - "@implement-comfyui-packaging"
  context: []
  priority: 2
  tags: []
  vcs_refs: []
  created_at: 2026-02-10T19:44:03.267Z
  started_at: 2026-02-11T02:44:49.090Z
  completed_at: 2026-02-11T02:49:00.440Z
  notes:
    - _ulid: 01KH4HA463N9QDME4T6H5MEV84
      created_at: 2026-02-10T19:44:03.267Z
      author: "@claude"
      content: |
        Implementation notes:

        Stub in nodes/entry.py. Architecture detection function should live in
        lib/arch_detect.py (or inline if small) -- inspect model.model_state_dict()
        keys for patterns: SDXL has input_blocks, middle_block, output_blocks;
        Z-Image has layers.N. plus noise_refiner; Flux has double_blocks; Qwen
        has transformer_blocks at depth 60. Check patterns in order of specificity
        (Z-Image before generic layers). For unsupported arch error, include first
        5 state dict key prefixes in the error message for debugging. ModelPatcher
        is stored as-is in RecipeBase (reference only, no clone, no tensor ops).
        Test by constructing MockModelPatcher instances with different key patterns
        and asserting detected arch.
        Files: nodes/entry.py, optionally lib/arch_detect.py.
    - _ulid: 01KH4J2TE18PEKWAPSGFSQG9N8
      created_at: 2026-02-10T19:57:32.482Z
      author: "@claude"
      content: "NF-1 scope clarification: v1 detects SDXL and Z-Image as supported architectures. Flux
        (double_blocks) and Qwen (transformer_blocks) should be detected and produce a clear
        UnsupportedArchitectureError with a message like 'Detected Flux architecture but no WIDEN
        loader is available yet. Supported: sdxl, zimage.' This way the detection code is
        future-proof but the error path is explicit."
      supersedes: null
    - _ulid: 01KH59FM8G8R54CKHG8BKP0BYQ
      created_at: 2026-02-11T02:46:29.393Z
      author: "@claude"
      content: "Implemented Entry Node with architecture detection. Created detect_architecture() function
        with pattern matching for SDXL (input_blocks/middle_block/output_blocks), Z-Image (layers +
        noise_refiner), Flux (double_blocks), and Qwen (60+ transformer_blocks). Flux/Qwen are
        detected but raise UnsupportedArchitectureError. Added 17 tests covering all 5 ACs: AC-1
        (returns RecipeBase), AC-2 (SDXL detection), AC-3 (Z-Image detection), AC-4 (no GPU/tensor
        copy), AC-5 (unsupported arch errors). All 107 tests pass, ruff clean."
      supersedes: null
  todos: []
  automation: eligible
- _ulid: 01KH4HA46729EXG3GT8QCW2F44
  slugs:
    - implement-lora-node
  title: Implement LoRA Node
  type: task
  spec_ref: "@lora-node"
  plan_ref: "@plan-widen-merge-feature-specs"
  status: completed
  blocked_by: []
  closed_reason: "Merged in PR #6. Implemented LoRA node with folder_paths dropdown, RecipeLoRA output
    with path/strength tuples, prev chaining for LoRA sets, and zero-strength preservation. All 5
    ACs have test coverage (12 tests total)."
  depends_on:
    - "@implement-testing-infrastructure"
    - "@implement-comfyui-packaging"
  context: []
  priority: 2
  tags: []
  vcs_refs: []
  created_at: 2026-02-10T19:44:03.271Z
  started_at: 2026-02-11T02:49:57.336Z
  completed_at: 2026-02-11T02:54:03.844Z
  notes:
    - _ulid: 01KH4HA467XDAB7ACFJRB2MXSN
      created_at: 2026-02-10T19:44:03.271Z
      author: "@claude"
      content: |
        Implementation notes:

        Stub in nodes/lora.py. The lora_name input must change from STRING type
        to use folder_paths.get_filename_list(loras) -- the ComfyUI pattern is:
        import folder_paths then lora_name: (folder_paths.get_filename_list(loras),)
        as a combo input. Full file path resolved at Exit time via
        folder_paths.get_full_path(loras, lora_name). The prev input receives a
        RecipeLoRA from a previous LoRA node -- extract its .loras tuple and
        concatenate: new_loras = prev.loras + (dict(path=lora_name, strength=strength),).
        If prev is None, create single-element tuple. For the task: update
        INPUT_TYPES to use folder_paths combo, implement add_lora() method,
        handle prev chaining with tuple concatenation. Edge case: prev might
        be None (optional input).
        Files: nodes/lora.py.
    - _ulid: 01KH59SQ5H65P189F8PK584N2V
      created_at: 2026-02-11T02:52:00.050Z
      author: "@claude"
      content: "Implemented LoRA node with folder_paths dropdown (deferred import for testability).
        add_lora() returns RecipeLoRA with proper prev chaining for LoRA sets. Added 12 tests
        covering all 5 ACs: AC-1 (returns RecipeLoRA with path/strength), AC-2 (chaining via prev),
        AC-3 (folder_paths dropdown), AC-4 (no prev = single-element), AC-5 (zero strength
        preserved). Updated conftest.py mock for folder_paths.get_filename_list. All 119 tests pass,
        ruff clean."
      supersedes: null
  todos: []
  automation: eligible
- _ulid: 01KH4HA46AAJBFFJ5JAVM9EM2H
  slugs:
    - implement-compose-node
  title: Implement Compose Node
  type: task
  spec_ref: "@compose-node"
  plan_ref: "@plan-widen-merge-feature-specs"
  status: completed
  blocked_by: []
  closed_reason: "Merged in PR #7. Implemented Compose node that accumulates branches for WIDEN
    merging. Uses RecipeCompose.with_branch() for persistent semantics. Validates branch types
    (accepts RecipeLoRA, RecipeCompose, RecipeMerge; rejects raw RecipeBase with helpful error). All
    4 ACs covered by 17 tests."
  depends_on:
    - "@implement-testing-infrastructure"
    - "@implement-comfyui-packaging"
  context: []
  priority: 2
  tags: []
  vcs_refs: []
  created_at: 2026-02-10T19:44:03.274Z
  started_at: 2026-02-11T02:54:56.746Z
  completed_at: 2026-02-11T02:58:53.235Z
  notes:
    - _ulid: 01KH4HA46B8WQXTZ2DPN615WVW
      created_at: 2026-02-10T19:44:03.275Z
      author: "@claude"
      content: |
        Implementation notes:

        Stub in nodes/compose.py. Implementation: if compose is provided and is a
        RecipeCompose, extract its .branches tuple and append the new branch:
        RecipeCompose(branches=compose.branches + (branch,)). If compose is None,
        create RecipeCompose(branches=(branch,)). For AC-4 validation: check
        isinstance(branch, RecipeBase) and raise ValueError with message about
        needing to apply LoRAs first or use as a Merge base input. Valid branch
        types: RecipeLoRA, RecipeCompose, RecipeMerge. Also validate that compose
        input when provided is a RecipeCompose (not some other recipe type).
        Files: nodes/compose.py.
    - _ulid: 01KH5A2DYSRP2EWMDA3H13K7NC
      created_at: 2026-02-11T02:56:45.530Z
      author: "@claude"
      content: "Implemented Compose node with branch validation and chaining. compose() uses
        RecipeCompose.with_branch() for persistent semantics. Added 17 tests covering all 4 ACs:
        AC-1 (single branch returns single-element tuple), AC-2 (appends to existing compose), AC-3
        (three chained nodes in order), AC-4 (RecipeBase rejected with helpful error). Also
        validates compose input is RecipeCompose. All 136 tests pass, ruff clean."
      supersedes: null
  todos: []
  automation: eligible
- _ulid: 01KH4HA46DNS18CPRTTECH915J
  slugs:
    - implement-merge-node
  title: Implement Merge Node
  type: task
  spec_ref: "@merge-node"
  plan_ref: "@plan-widen-merge-feature-specs"
  status: completed
  blocked_by: []
  closed_reason: "Merged in PR #8. Implemented Merge node with base/target type validation. merge()
    validates base is RecipeBase or RecipeMerge (rejects RecipeLoRA/RecipeCompose with helpful error
    message suggesting Entry node or Merge output). All 6 ACs covered by 23 tests: AC-1 (RecipeMerge
    with fields), AC-2 (no backbone defaults None), AC-3 (backbone stored), AC-4 (merge chaining),
    AC-5 (invalid base rejection), AC-6 (t_factor -1.0 preserved). All tests pass, ruff clean."
  depends_on:
    - "@implement-testing-infrastructure"
    - "@implement-comfyui-packaging"
  context: []
  priority: 2
  tags: []
  vcs_refs: []
  created_at: 2026-02-10T19:44:03.277Z
  started_at: 2026-02-11T02:59:47.138Z
  completed_at: 2026-02-11T03:04:40.091Z
  notes:
    - _ulid: 01KH4HA46D87PGPQBEVJMMND53
      created_at: 2026-02-10T19:44:03.277Z
      author: "@claude"
      content: |
        Implementation notes:

        Stub in nodes/merge.py. Implementation: validate base is RecipeBase or
        RecipeMerge (raise ValueError with specific message if not). Validate
        target is RecipeLoRA, RecipeCompose, or RecipeMerge (not RecipeBase).
        Then construct RecipeMerge(base=base, target=target, backbone=backbone,
        t_factor=t_factor). The t_factor slider range is -1.0 to 5.0, step 0.05
        (already correct in stub). -1.0 means passthrough -- interpreted by Exit
        node, not Merge node. Backbone defaults to None when not connected
        (optional input). For the task: add isinstance validation checks at top
        of merge(), construct and return RecipeMerge.
        Files: nodes/merge.py.
    - _ulid: 01KH5ABPDGFY83D0SQ5XDGRMG2
      created_at: 2026-02-11T03:01:49.105Z
      author: "@claude"
      content: "Implemented Merge node with base/target type validation. merge() validates base is
        RecipeBase or RecipeMerge (rejects RecipeLoRA/RecipeCompose with helpful error), accepts
        RecipeLoRA/RecipeCompose/RecipeMerge as target. All 6 ACs covered by 23 tests: AC-1 (returns
        RecipeMerge with fields), AC-2 (no backbone defaults None), AC-3 (backbone stored when
        provided), AC-4 (merge chaining via base), AC-5 (RecipeLoRA/RecipeCompose rejected as base),
        AC-6 (t_factor -1.0 preserved). All 159 tests pass, ruff clean."
      supersedes: null
  todos: []
  automation: eligible
- _ulid: 01KH4HA46HJ6V0VC67XRPWSGB5
  slugs:
    - implement-exit-node
  title: Implement Exit Node
  type: task
  spec_ref: "@exit-node"
  plan_ref: "@plan-widen-merge-feature-specs"
  status: pending
  blocked_by: []
  depends_on:
    - "@implement-exit-recipe-analysis"
    - "@implement-exit-batched-evaluation"
    - "@implement-exit-patch-installation"
    - "@implement-comfyui-packaging"
  context: []
  priority: 2
  tags: []
  vcs_refs: []
  created_at: 2026-02-10T19:44:03.281Z
  notes:
    - _ulid: 01KH4HA46HK4H347XYD1D7VY9S
      created_at: 2026-02-10T19:44:03.281Z
      author: "@claude"
      content: |
        Implementation notes:

        Stub in nodes/exit.py. This is the most complex node -- it orchestrates
        everything. The execute() method: (1) Validate recipe tree structure by
        walking recursively and checking types at each node. (2) Call batched
        executor from lib/executor.py which handles phases 1-3. (3) Install
        results as set patches on a ModelPatcher clone. The IS_CHANGED classmethod
        must walk recipe tree to find all RecipeLoRA nodes, resolve file paths via
        folder_paths.get_full_path(loras, name), and return hash of (mtime, size)
        tuples. Use os.path.getmtime() and os.path.getsize(). If any file missing,
        return float(NaN) to force re-execution. Progress reporting via
        comfy.utils.ProgressBar(total_steps) -- get total from executor. Downstream
        LoRA compat: set patches work because ComfyUI calculate_weight() processes
        patches in list order -- set replaces first, then subsequent LoRA patches
        add on top. Depends on lib/executor.py, lib/recipe.py, all node implementations.
        Files: nodes/exit.py.
    - _ulid: 01KH4J2YGZ6J2K44BEG1QRPB5N
      created_at: 2026-02-10T19:57:36.671Z
      author: "@claude"
      content: "NF-3 scope clarification: This task implements the WIDENExitNode class shell in
        nodes/exit.py ONLY — INPUT_TYPES, RETURN_TYPES, the execute() method that validates the
        recipe tree then delegates to lib/executor.py, the IS_CHANGED classmethod, and progress bar
        setup. The actual executor internals (recipe analysis, batched evaluation, patch
        installation) are implemented in separate sub-requirement tasks that write to
        lib/executor.py. This task wires the node to the executor, it does not implement the
        executor."
      supersedes: null
  todos: []
  automation: eligible
- _ulid: 01KH4HA46PY9P8S7PZ0D32WZDD
  slugs:
    - implement-exit-recipe-analysis
  title: Implement Exit Recipe Analysis
  type: task
  spec_ref: "@exit-recipe-analysis"
  plan_ref: "@plan-widen-merge-feature-specs"
  status: pending
  blocked_by: []
  depends_on:
    - "@implement-architecture-specific-lora-loaders"
  context: []
  priority: 2
  tags: []
  vcs_refs: []
  created_at: 2026-02-10T19:44:03.286Z
  notes:
    - _ulid: 01KH4HA46PWH5STPRD10BPGH8X
      created_at: 2026-02-10T19:44:03.286Z
      author: "@claude"
      content: |
        Implementation notes:

        This phase happens at start of execute() in nodes/exit.py or in
        lib/executor.py entry point. Tree walk: recursive function following
        RecipeMerge.base links until hitting RecipeBase. Collect all RecipeLoRA
        nodes by walking .target and .base recursively. Set ID assignment:
        identity-based -- with frozen dataclasses, chained LoRAs produce a single
        RecipeLoRA with a multi-element tuple, so each unique RecipeLoRA instance
        equals one set. LoRA loading: select loader from lib/lora/{arch}.py based
        on RecipeBase.arch. Resolve file paths with folder_paths.get_full_path(loras,
        name). Build affected-key map by calling loader.affected_keys for each set.
        The tree walk and set ID assignment is the most critical piece -- get the
        identity semantics right.
        Files: lib/executor.py, references lib/lora/base.py interface.
  todos: []
  automation: eligible
- _ulid: 01KH4HA46X4V9RHXW26VP36FD9
  slugs:
    - implement-exit-batched-evaluation
  title: Implement Exit Batched Evaluation
  type: task
  spec_ref: "@exit-batched-eval"
  plan_ref: "@plan-widen-merge-feature-specs"
  status: pending
  blocked_by: []
  depends_on:
    - "@implement-batched-pipeline-executor"
    - "@implement-exit-recipe-analysis"
  context: []
  priority: 2
  tags: []
  vcs_refs: []
  created_at: 2026-02-10T19:44:03.293Z
  notes:
    - _ulid: 01KH4HA46X9JT6J2TFQA337BTM
      created_at: 2026-02-10T19:44:03.293Z
      author: "@claude"
      content: |
        Implementation notes:

        This is the inner evaluation loop in lib/executor.py. For each OpSignature
        group, for each chunk of B keys: stack base tensors to GPU, walk recipe
        tree recursively. Tree walker dispatches on recipe node type: RecipeMerge
        with RecipeCompose target -> evaluate each branch then call
        widen.merge_weights_batched() (or filter_delta_batched if single branch).
        RecipeMerge with RecipeLoRA target -> call _apply_lora_set_batched_gpu()
        to get delta then widen.filter_delta_batched(). Chain: if RecipeMerge.base
        is another RecipeMerge, recurse on inner merge first. Backbone: use
        RecipeMerge.backbone if not None, else use base tensor. Port recursive
        evaluation from merge-router evaluate_node_batched() (~lines 850-950 of
        scripts/lora_chain_merge.py), adapting from config dict traversal to
        recipe dataclass traversal.
        Files: lib/executor.py.
    - _ulid: 01KH4J3H45X4PGJCNH8W986KB6
      created_at: 2026-02-10T19:57:55.717Z
      author: "@claude"
      content: "NF-6 boundary clarification: This task implements the RECIPE TREE WALKER in
        lib/executor.py — the evaluate_node_batched() function (~line 850 in merge-router
        scripts/lora_chain_merge.py) adapted for recipe dataclasses. It dispatches to primitives
        from @implement-batched-pipeline-executor (OpSignature grouping,
        _apply_lora_set_batched_gpu, compute_batch_size) and WIDEN functions from
        @implement-widen-core-algorithm (filter_delta_batched, merge_weights_batched). This task is
        the glue between recipe traversal and the batched primitives. Also handles backbone
        override: when RecipeMerge.backbone is not None, pass it as the importance reference to
        WIDEN functions instead of the base tensor."
      supersedes: null
  todos: []
  automation: eligible
- _ulid: 01KH4HA4733VECXNH5H4M4AA2B
  slugs:
    - implement-exit-patch-installation
  title: Implement Exit Patch Installation
  type: task
  spec_ref: "@exit-patch-install"
  plan_ref: "@plan-widen-merge-feature-specs"
  status: completed
  blocked_by: []
  closed_reason: "Merged in PR #9. Implemented install_merged_patches() helper with ModelPatcher
    cloning, diffusion_model. key prefixing, CPU transfer, and base dtype matching. Added IS_CHANGED
    classmethod using SHA-256 hash of LoRA file (path, mtime, size) tuples for cache invalidation.
    All 6 acceptance criteria covered by 26 tests."
  depends_on:
    - "@implement-testing-infrastructure"
  context: []
  priority: 2
  tags: []
  vcs_refs: []
  created_at: 2026-02-10T19:44:03.299Z
  started_at: 2026-02-11T03:05:39.107Z
  completed_at: 2026-02-11T03:10:24.420Z
  notes:
    - _ulid: 01KH4HA473ZK9FSNE9X2012HTK
      created_at: 2026-02-10T19:44:03.299Z
      author: "@claude"
      content: |
        Implementation notes:

        After batched evaluation produces dict of {key: merged_tensor_on_gpu},
        transfer each to CPU with .cpu(), cast to base model storage dtype with
        .to(base_dtype). Get base dtype from first value in
        model_patcher.model_state_dict(). Clone model: merged = model_patcher.clone().
        Build patch dict: {f"diffusion_model.{k}": ("set", tensor) for k, tensor in
        merged_state.items()}. Install: merged.add_patches(patches, strength_patch=1.0).
        Note: the set patch format for add_patches is a tuple (strength, ("set", tensor),
        strength_model, None, None) -- check that add_patches handles the format or if
        raw tuple is needed. Verify against ComfyUI comfy/model_patcher.py add_patches
        and comfy/lora.py calculate_weight for exact format. IS_CHANGED: implement as
        @classmethod on WIDENExitNode -- receives same args as execute(). Walk recipe
        to collect all LoRA file paths, compute hashlib.sha256 of (path, mtime, size)
        tuples sorted by path. Return hex digest.
        Files: nodes/exit.py.
    - _ulid: 01KH5AQ1QPKBHNYK5HPDFVY9QX
      created_at: 2026-02-11T03:08:01.142Z
      author: "@claude"
      content: "Implemented install_merged_patches() helper and IS_CHANGED classmethod.
        install_merged_patches clones ModelPatcher, builds set patches with diffusion_model. prefix,
        transfers tensors to CPU and casts to base dtype. IS_CHANGED walks recipe tree to collect
        LoRA paths, computes SHA-256 hash from (path, mtime, size) tuples for cache key. All 6 ACs
        covered by 26 tests: AC-1 (clone and set patches), AC-2 (diffusion_model. prefix), AC-3 (CPU
        transfer), AC-4 (dtype matching), AC-5 (identical hash on no changes), AC-6 (different hash
        on modifications). All 185 tests pass, ruff clean."
      supersedes: null
  todos: []
  automation: eligible
- _ulid: 01KH4HA47BN0SVNJWSRGXBNJ2W
  slugs:
    - implement-widen-core-algorithm
  title: Implement WIDEN Core Algorithm
  type: task
  spec_ref: "@widen-core"
  plan_ref: "@plan-widen-merge-feature-specs"
  status: completed
  blocked_by: []
  closed_reason: "Merged in PR #4. Implemented WIDEN core algorithm port from merge-router with 5
    modules (numerical_config.py, sparsity.py, ranking.py, divergence.py, widen.py). All 9 ACs
    covered with 32 tests: filter_delta zeros low-importance (AC-1), merge_weights routes via
    softmax (AC-2), batched variants match per-key (AC-3), no ComfyUI imports (AC-4), deterministic
    behavior (AC-5), fp16/bf16 use fp32 (AC-6), default config values (AC-7), filter_delta_batched
    fallback (AC-8), merge_weights_batched fallback (AC-9)."
  depends_on: []
  context: []
  priority: 1
  tags: []
  vcs_refs: []
  created_at: 2026-02-10T19:44:03.307Z
  started_at: 2026-02-11T02:33:53.360Z
  completed_at: 2026-02-11T02:43:54.707Z
  notes:
    - _ulid: 01KH4HA47BCY6NJ4SPY12G85HM
      created_at: 2026-02-10T19:44:03.307Z
      author: "@claude"
      content: |
        Implementation notes:

        Port from ~/Projects/merge-router/src/core/widen.py. Key classes/functions
        to port: WIDEN class with filter_delta(), merge_weights(),
        filter_delta_batched(), merge_weights_batched(), _disentangle(),
        _rank_importance(), _calibrate(). Also port WIDENConfig dataclass with
        fields: n_models, t_factor, s_calibration, ranking_strategy,
        sparsity_method, calibration_mode, dtype. Port supporting modules:
        lib/divergence.py from src/core/divergence.py (divergence metrics),
        lib/ranking.py from src/core/ranking.py (ranking mechanisms),
        lib/numerical_config.py from src/core/numerical_config.py (eps values
        per dtype). Strip: any CLI imports, config file parsing, logging setup
        (use stdlib logging). Keep: all torch operations, numerical stability
        handling (upcast to fp32 for computation, downcast result back), batched
        variants operating on [B, *shape] tensors. Fallback behavior (AC-8, AC-9)
        from merge-router lines ~905-928 in scripts/lora_chain_merge.py -- wrap
        batched WIDEN calls in try/except, on non-OOM error fall back to passthrough
        (filter_delta) or averaging (merge_weights), log warning via logging.warning().
        Test by creating small synthetic tensors (e.g., 8x8 float32) and verifying
        filter_delta zeros low-importance entries, merge_weights routes correctly.
        Compare against merge-router by running both on same input and checking allclose.
        Files: lib/widen.py, lib/divergence.py, lib/ranking.py, lib/numerical_config.py.
    - _ulid: 01KH4J2PAHPASF7QZ33EHV4RNX
      created_at: 2026-02-10T19:57:28.274Z
      author: "@claude"
      content: "NF-2 fix: Also port lib/sparsity.py from src/core/sparsity.py (sparsemax, entmax). This
        was listed in design doc S5 as required core algorithm but was missing from the files list.
        WIDENConfig.sparsity_method references it."
      supersedes: null
    - _ulid: 01KH594A77M5WRDPVMXZMD506W
      created_at: 2026-02-11T02:40:18.663Z
      author: "@claude"
      content: "Implemented WIDEN core algorithm port from merge-router. Created 5 modules:
        numerical_config.py (epsilon handling), sparsity.py (sparsemax/entmax), ranking.py
        (importance ranking), divergence.py (direction divergence), widen.py (main algorithm). Added
        32 tests covering all 9 ACs: filter_delta zeros low-importance (AC-1), merge_weights routes
        via softmax (AC-2), batched variants match per-key (AC-3), no ComfyUI imports (AC-4),
        deterministic behavior (AC-5), fp16/bf16 use fp32 (AC-6), default config values (AC-7),
        filter_delta_batched fallback (AC-8), merge_weights_batched fallback (AC-9). All 90 tests
        pass, ruff clean."
      supersedes: null
  todos: []
  automation: eligible
- _ulid: 01KH4HA47F493S53EWKW4EA9SF
  slugs:
    - implement-batched-pipeline-executor
  title: Implement Batched Pipeline Executor
  type: task
  spec_ref: "@batched-executor"
  plan_ref: "@plan-widen-merge-feature-specs"
  status: completed
  blocked_by: []
  closed_reason: "Merged in PR #10. Implemented batched pipeline executor primitives: OpSignature
    (parameter grouping), DeltaSpec (LoRA delta specs), compile_batch_groups (shape/affecting_sets
    grouping), compute_batch_size (70% VRAM targeting), apply_lora_batch_gpu (torch.bmm for standard
    LoRA, torch.kron for LoKr), and chunked_evaluation (OOM backoff wrapper). All 7 ACs covered by
    30 tests."
  depends_on:
    - "@implement-widen-core-algorithm"
    - "@implement-testing-infrastructure"
  context: []
  priority: 2
  tags: []
  vcs_refs: []
  created_at: 2026-02-10T19:44:03.311Z
  started_at: 2026-02-11T03:11:31.166Z
  completed_at: 2026-02-11T03:18:03.688Z
  notes:
    - _ulid: 01KH4HA47F0N4G7WDBRY8CRMCT
      created_at: 2026-02-10T19:44:03.311Z
      author: "@claude"
      content: |
        Implementation notes:

        Port from ~/Projects/merge-router/scripts/lora_chain_merge.py. Key pieces:
        OpSignature frozen dataclass with affecting_sets (frozenset), shape (tuple),
        ndim (int). DeltaSpec dataclass with fields for LoRA factors (up, down,
        scale, alpha, kind, rank, key_index). compute_batch_size(shape, n_models,
        dtype, free_vram) formula: B = floor(free_vram * 0.7 / (numel(shape) *
        dtype_bytes * (3 + 3 * n_models))). _apply_lora_set_batched_gpu(base_batch,
        delta_specs, ...) -- partition specs by (kind, rank), stack up/down matrices,
        torch.bmm(down, up) for standard LoRA, torch.kron per-key for LoKr, scatter
        deltas back by key_index. OOM backoff: wrap chunk evaluation in try/except
        torch.cuda.OutOfMemoryError, on catch call torch.cuda.empty_cache() and retry
        with B=1. Define DeltaSpec in lib/types.py or lib/executor.py and import from
        lib/lora/ loaders. The executor is the main integration point -- it calls into
        lib/widen.py for WIDEN ops, lib/lora/*.py for LoRA loading, and walks the
        recipe tree from lib/recipe.py.
        Files: lib/executor.py, lib/types.py (for DeltaSpec/OpSignature if shared).
    - _ulid: 01KH4J3CTXKYTG9DN1GYM6W95A
      created_at: 2026-02-10T19:57:51.325Z
      author: "@claude"
      content: "NF-6 boundary clarification: This task implements the PRIMITIVES in lib/executor.py —
        OpSignature dataclass, DeltaSpec (in lib/types.py), compute_batch_size(),
        _apply_lora_set_batched_gpu() (LoRA apply via torch.bmm, LoKr via torch.kron), and OOM
        backoff wrapper. It does NOT implement the recipe tree walker — that is in
        @implement-exit-batched-evaluation. Key functions to port from scripts/lora_chain_merge.py:
        OpSignature (~line 50), DeltaSpec (~line 70), compute_batch_size() (~line 200),
        _apply_lora_set_batched_gpu() (~line 400). The evaluate_node_batched() tree walker (~line
        850) belongs to the exit-batched-eval task."
      supersedes: null
    - _ulid: 01KH5B4X0XS2GN6M3S54F4P0SM
      created_at: 2026-02-11T03:15:35.069Z
      author: "@claude"
      content: "Implemented batched pipeline executor primitives in lib/executor.py. Created OpSignature
        (frozen dataclass for parameter grouping by shape/affecting_sets), DeltaSpec (LoRA delta
        specification), compile_batch_groups (groups keys by OpSignature), compute_batch_size
        (targets 70% free VRAM), apply_lora_batch_gpu (torch.bmm for standard LoRA, torch.kron for
        LoKr), and chunked_evaluation (OOM backoff wrapper with CPU result transfer and dtype
        matching). All 7 ACs covered by 30 tests: AC-1 (grouping), AC-2 (bmm), AC-3 (70% VRAM), AC-4
        (OOM backoff), AC-5 (CPU results), AC-6 (dtype matching), AC-7 (LoKr kron). All 215 tests
        pass, ruff clean."
      supersedes: null
  todos: []
  automation: eligible
- _ulid: 01KH4HA47M05Q979790FR6MC9J
  slugs:
    - implement-architecture-specific-lora-loaders
  title: Implement Architecture-Specific LoRA Loaders
  type: task
  spec_ref: "@lora-loaders"
  plan_ref: "@plan-widen-merge-feature-specs"
  status: in_progress
  blocked_by: []
  depends_on:
    - "@implement-testing-infrastructure"
  context: []
  priority: 2
  tags: []
  vcs_refs: []
  created_at: 2026-02-10T19:44:03.316Z
  notes:
    - _ulid: 01KH4HA47M869P70TBAPP53GVA
      created_at: 2026-02-10T19:44:03.316Z
      author: "@claude"
      content: |
        Implementation notes:

        Define loader interface in lib/lora/base.py as an abstract base class or
        protocol: class LoRALoader(ABC) with @abstractmethod load(self, path, strength),
        @property affected_keys -> set[str], get_delta_specs(self, keys) -> list[DeltaSpec],
        cleanup(self). Each architecture implements in its own module. DeltaSpec
        dataclass (in lib/types.py or lib/executor.py) needs: key, key_index, kind
        (standard/lokr/qkv), rank, up (Tensor), down (Tensor), scale, alpha, offset
        (optional tuple for QKV). Loader selection: simple dict lookup in executor
        like {"sdxl": SDXLLoader, "zimage": ZImageLoader}. For AC-3 pluggable design:
        use registry pattern or just the dict -- adding new arch means adding one entry.
        Files: lib/lora/base.py, lib/lora/__init__.py (registry).
  todos: []
  automation: eligible
  started_at: 2026-02-11T03:18:49.921Z
- _ulid: 01KH4HA47ST02A5Y0G5ZABFP2D
  slugs:
    - implement-sdxl-lora-loader
  title: Implement SDXL LoRA Loader
  type: task
  spec_ref: "@sdxl-loader"
  plan_ref: "@plan-widen-merge-feature-specs"
  status: pending
  blocked_by: []
  depends_on:
    - "@implement-architecture-specific-lora-loaders"
  context: []
  priority: 2
  tags: []
  vcs_refs: []
  created_at: 2026-02-10T19:44:03.321Z
  notes:
    - _ulid: 01KH4HA47S0BBEWY8JBW0KCWSB
      created_at: 2026-02-10T19:44:03.321Z
      author: "@claude"
      content: |
        Implementation notes:

        Port from merge-router or implement fresh. SDXL LoRA key mapping: keys follow
        patterns like lora_unet_input_blocks_0_0_op.lora_down.weight -> base key
        input_blocks.0.0.weight. ComfyUI own comfy/lora.py has model_lora_keys_unet()
        that builds this mapping. Options: (1) Use ComfyUI key mapping function and
        wrap in our loader interface, (2) Implement standalone for consistency.
        Recommend option (1) for SDXL since ComfyUI handles all edge cases (attention,
        proj_in/out, time_embed). Load safetensors with safetensors.torch.load_file(),
        map keys, extract up/down/alpha per key, construct DeltaSpec objects. Standard
        LoRA: kind=standard, up=lora_up.weight, down=lora_down.weight, alpha from lora
        key or default to rank.
        Files: lib/lora/sdxl.py.
  todos: []
  automation: eligible
- _ulid: 01KH4HA47Z3DSGDJ07S2V7DNRD
  slugs:
    - implement-z-image-lora-loader
  title: Implement Z-Image LoRA Loader
  type: task
  spec_ref: "@zimage-loader"
  plan_ref: "@plan-widen-merge-feature-specs"
  status: pending
  blocked_by: []
  depends_on:
    - "@implement-architecture-specific-lora-loaders"
  context: []
  priority: 2
  tags: []
  vcs_refs: []
  created_at: 2026-02-10T19:44:03.327Z
  notes:
    - _ulid: 01KH4HA47ZYK7SM6X6WGWT9GZ8
      created_at: 2026-02-10T19:44:03.327Z
      author: "@claude"
      content: |
        Implementation notes:

        Port from ~/Projects/merge-router/scripts/zimage_lora_merge.py. Key function:
        _parse_lora_key(key) which maps Diffusers LoRA key names to S3-DiT base model
        keys and identifies QKV components. Z-Image base model uses fused
        attention.qkv.weight (11520x3840 = 3x3840) but LoRAs have separate
        to_q/to_k/to_v. The loader must: (1) Parse each LoRA key to identify
        target parameter and QKV component. (2) For QKV keys, create DeltaSpecs
        with kind=qkv and offset=(0, q_start, q_len) indicating which third of
        the fused weight this LoRA targets. The offset tuple is (dimension=0,
        start, length) where start is 0/3840/7680 for q/k/v respectively and
        length is 3840. (3) Handle non-QKV keys (FFN, norm, etc.) as standard
        LoRA. Also handle LoKr weights if present -- these have lokr_w1, lokr_w2
        instead of lora_up/lora_down, use kind=lokr. The Diffusers key mapping
        handles patterns like transformer_blocks.0.attn.to_q -> layers.0.attention.qkv
        (with offset for q portion).
        Files: lib/lora/zimage.py.
  todos: []
  automation: eligible
- _ulid: 01KH4HA4865JG16KMN5YXENCYH
  slugs:
    - implement-memory-management
  title: Implement Memory Management
  type: task
  spec_ref: "@memory-management"
  plan_ref: "@plan-widen-merge-feature-specs"
  status: pending
  blocked_by: []
  depends_on:
    - "@implement-exit-node"
  context: []
  priority: 2
  tags: []
  vcs_refs: []
  created_at: 2026-02-10T19:44:03.334Z
  notes:
    - _ulid: 01KH4HA486XCQMBVVXJ4R3TJHM
      created_at: 2026-02-10T19:44:03.334Z
      author: "@claude"
      content: |
        Implementation notes:

        Memory management is woven throughout lib/executor.py. Key patterns to port
        from merge-router scripts/lora_chain_merge.py: (1) Per-chunk cleanup: after
        transferring results to CPU, explicitly del base_batch and gpu intermediates
        then gc.collect() and torch.cuda.empty_cache(). (2) Per-group cleanup: between
        OpSignature groups, call gc.collect() + torch.cuda.empty_cache(). (3) Loader
        cleanup: after evaluation completes, call loader.cleanup() for each loader
        (which calls clear_delta_cache() and drops cached LoRA state). (4) Final
        cleanup: ensure returned merged_state dict contains only CPU tensors. The
        merge-router source has ~8 explicit gc.collect/empty_cache calls -- identify
        each and port the pattern. For AC-5 testing: use torch.cuda.max_memory_allocated()
        before/after chunk and compare to compute_batch_size prediction. This is a
        cross-cutting concern -- its ACs affect implementation in lib/executor.py
        primarily, also nodes/exit.py (loader cleanup after execute completes) and
        lib/lora/base.py (cleanup interface).
        Files: lib/executor.py (primary), nodes/exit.py (loader teardown),
        lib/lora/base.py (cleanup interface).
    - _ulid: 01KH4J4HP1J0TQVSKK15FKXETY
      created_at: 2026-02-10T19:58:29.057Z
      author: "@claude"
      content: "NF-7 restructured: This task is now a HARDENING PASS that runs AFTER exit-node integration
        works. It is no longer a prerequisite for exit-node. First get the pipeline working with
        basic cleanup, then this task adds comprehensive memory management:
        gc.collect()/torch.cuda.empty_cache() calls per-chunk and per-group, loader.cleanup()
        teardown, GPU tensor leak verification. This task reviews lib/executor.py and nodes/exit.py
        to add the ~8 cleanup points from merge-router's pattern."
      supersedes: null
  todos: []
  automation: eligible
- _ulid: 01KH4HA48ERX1APFPSJS5E1Y7F
  slugs:
    - implement-per-block-control
  title: Implement Per-Block Control
  type: task
  spec_ref: "@per-block-control"
  plan_ref: "@plan-widen-merge-feature-specs"
  status: pending
  blocked_by: []
  depends_on:
    - "@implement-block-config-type"
    - "@implement-comfyui-packaging"
    - "@implement-testing-infrastructure"
  context: []
  priority: 3
  tags: []
  vcs_refs: []
  created_at: 2026-02-10T19:44:03.342Z
  notes:
    - _ulid: 01KH4HA48EJA9E7AFC4E38BA13
      created_at: 2026-02-10T19:44:03.342Z
      author: "@claude"
      content: |
        Implementation notes:

        Adds BLOCK_CONFIG custom ComfyUI type. Architecture-specific config nodes
        go in nodes/block_config_sdxl.py, nodes/block_config_zimage.py. Each
        exposes sliders for its architecture block groups: SDXL has input_blocks
        (groups of 3: IN00-02, IN03-05, IN06-08), middle_block, output_blocks
        (groups of 3). Z-Image has layers (groups of 5: L00-04, L05-09, ... L25-29),
        noise_refiner, context_refiner. Each slider FLOAT range 0.0-2.0, step 0.05.
        ComfyUI allows typing values outside slider range so -1.0 is accessible.
        The node produces a BlockConfig dataclass (in lib/recipe.py). Backwards
        compatibility: when block_config fields on RecipeMerge/RecipeLoRA are None,
        executor uses global t_factor/strength -- no special casing needed.
        Files: nodes/block_config_sdxl.py, nodes/block_config_zimage.py,
        lib/recipe.py (BlockConfig dataclass).
  todos: []
  automation: eligible
- _ulid: 01KH4HA48PV4PF188MY0H239GA
  slugs:
    - implement-block-config-type
  title: Implement Block Config Type
  type: task
  spec_ref: "@block-config-type"
  plan_ref: "@plan-widen-merge-feature-specs"
  status: pending
  blocked_by: []
  depends_on:
    - "@implement-recipe-type-system"
  context: []
  priority: 3
  tags: []
  vcs_refs: []
  created_at: 2026-02-10T19:44:03.350Z
  notes:
    - _ulid: 01KH4HA48PDVTJC03SWE79A21X
      created_at: 2026-02-10T19:44:03.350Z
      author: "@claude"
      content: |
        Implementation notes:

        Add to lib/recipe.py: @dataclass(frozen=True) class BlockConfig with fields
        arch (str), block_overrides (tuple), layer_type_overrides (tuple). The
        block_overrides is a tuple of (block_pattern, value) pairs e.g.,
        (("IN00-02", 0.5), ("MID", 1.0), ...). The layer_type_overrides is a tuple
        of (layer_type, value) pairs for cross-cutting layer type control (attention,
        feed_forward, norm, etc.). Add block_config: object = None field to both
        RecipeLoRA and RecipeMerge -- since frozen, this means defining new versions
        with the additional field. Field defaults to None for backwards compat. The
        arch field must match RecipeBase.arch -- validated at Exit time.
        Files: lib/recipe.py.
  todos: []
  automation: eligible
- _ulid: 01KH4HA48WYR6H4E0QV888VSD2
  slugs:
    - implement-merge-per-block-t-factor
  title: Implement Merge Per-Block T-Factor
  type: task
  spec_ref: "@merge-block-config"
  plan_ref: "@plan-widen-merge-feature-specs"
  status: pending
  blocked_by: []
  depends_on:
    - "@implement-per-block-control"
    - "@implement-merge-node"
    - "@implement-exit-node"
  context: []
  priority: 3
  tags: []
  vcs_refs: []
  created_at: 2026-02-10T19:44:03.356Z
  notes:
    - _ulid: 01KH4HA48WEV45JBSVZ5N8XDQ1
      created_at: 2026-02-10T19:44:03.356Z
      author: "@claude"
      content: |
        Implementation notes:

        Merge node gains optional block_t_factor input of type BLOCK_CONFIG in
        INPUT_TYPES. When present, stored in RecipeMerge.block_config. At Exit
        evaluation time, for each parameter key, executor: (1) classifies key into
        block group using architecture-specific patterns (e.g., for SDXL
        input_blocks.3. -> IN03-05), (2) looks up block group in
        BlockConfig.block_overrides, (3) uses override value as t_factor instead
        of global RecipeMerge.t_factor. If key block group not in overrides, falls
        back to global t_factor. Block classification function should live in
        lib/block_classify.py with one function per arch.
        Files: nodes/merge.py (add input), lib/executor.py (use block config
        during eval), lib/block_classify.py (key-to-block mapping).
  todos: []
  automation: eligible
- _ulid: 01KH4HA493AA51NFWN2NGQA6GA
  slugs:
    - implement-lora-per-block-strength
  title: Implement LoRA Per-Block Strength
  type: task
  spec_ref: "@lora-block-config"
  plan_ref: "@plan-widen-merge-feature-specs"
  status: pending
  blocked_by: []
  depends_on:
    - "@implement-per-block-control"
    - "@implement-lora-node"
    - "@implement-exit-node"
  context: []
  priority: 3
  tags: []
  vcs_refs: []
  created_at: 2026-02-10T19:44:03.363Z
  notes:
    - _ulid: 01KH4HA49389ZJ52761QNKPQ3X
      created_at: 2026-02-10T19:44:03.363Z
      author: "@claude"
      content: |
        Implementation notes:

        LoRA node gains optional block_strength input of type BLOCK_CONFIG in
        INPUT_TYPES. When present, stored in RecipeLoRA.block_config. At Exit time
        during batched LoRA apply phase (_apply_lora_set_batched_gpu), for each
        parameter key in batch: (1) classify key into block group, (2) look up
        override strength in BlockConfig, (3) multiply LoRA delta by per-block
        strength instead of global strength. This scales LoRA contribution before
        WIDEN sees it. During DeltaSpec processing, scale each spec effective
        strength by per-block override. Since batching groups keys by OpSignature
        (same shape + affecting sets), and per-block strength varies by key, need
        to apply scaling per-key within batch -- either as diagonal scaling matrix
        or by splitting batch by block group.
        Files: nodes/lora.py (add input), lib/executor.py (per-block scaling
        in LoRA apply).
    - _ulid: 01KH4J41ABBBKTGH8J7ZTBNFB0
      created_at: 2026-02-10T19:58:12.299Z
      author: "@claude"
      content: "NF-8 design decision resolved: Apply per-block strength as a per-key scaling vector within
        the batch. After computing the LoRA delta for the full batch via torch.bmm, multiply each
        key's delta by its per-block strength scalar. The scaling vector is constructed during
        recipe analysis by classifying each key to a block group via lib/block_classify.py and
        looking up the BlockConfig override. This avoids splitting the batch and preserves the bmm
        optimization. Implementation: after _apply_lora_set_batched_gpu() returns the delta batch
        [B, *shape], compute a strength vector [B, 1, 1] from per-key block classifications, then
        multiply: delta_batch *= strength_vector."
      supersedes: null
  todos: []
  automation: eligible
- _ulid: 01KH508VE1GEDSBP3VENYEF2R0
  slugs:
    - implement-comfyui-mocking-and-fixtures
  title: Implement ComfyUI Mocking and Fixtures
  type: task
  spec_ref: "@comfyui-mocking"
  plan_ref: "@plan-testing-strategy"
  status: pending
  blocked_by: []
  depends_on:
    - "@implement-testing-infrastructure"
    - "@implement-recipe-type-system"
  context: []
  priority: 3
  tags: []
  vcs_refs: []
  created_at: 2026-02-11T00:05:30.177Z
  notes:
    - _ulid: 01KH508VE1T9JEBJV2R50E10ZD
      created_at: 2026-02-11T00:05:30.177Z
      author: "@claude"
      content: |
        Implementation notes:

        Use ComfyUI's own pattern from tests-unit/ and ComfyUI_Selectors:
        sys.modules patching in conftest.py before node imports. MockModelPatcher
        should use small tensors (4x4 float32) for speed. Recipe fixtures build
        on lib/recipe.py dataclasses. Arch fixtures provide representative state
        dict key sets for detection testing.
        Files: tests/conftest.py, tests/mocks/__init__.py, tests/mocks/mock_comfy.py
  todos: []
  automation: eligible
- _ulid: 01KH508VEVHA4ZME2CDZ275XKS
  slugs:
    - implement-node-graph-testing
  title: Implement Node Graph Testing
  type: task
  spec_ref: "@node-graph-testing"
  plan_ref: "@plan-testing-strategy"
  status: pending
  blocked_by: []
  depends_on:
    - "@implement-comfyui-mocking-and-fixtures"
    - "@implement-entry-node"
    - "@implement-lora-node"
    - "@implement-compose-node"
    - "@implement-merge-node"
  context: []
  priority: 3
  tags: []
  vcs_refs: []
  created_at: 2026-02-11T00:05:30.203Z
  notes:
    - _ulid: 01KH508VEVQ633FW8E9Y3NX9TP
      created_at: 2026-02-11T00:05:30.203Z
      author: "@claude"
      content: |
        Implementation notes:

        Create tests/test_graph.py with helper functions that instantiate node
        classes and call their FUNCTION methods directly to build recipe trees.
        The mock executor is a lightweight tree walker (separate from the real
        executor) that returns an operation plan (list of {op: filter_delta|merge_weights,
        keys: ...}) without touching GPU. This validates the Exit node's recipe
        analysis logic independently.
        Files: tests/test_graph.py, tests/helpers/graph_builder.py
  todos: []
  automation: eligible
- _ulid: 01KH508VFBCS29YV4HX4J1QTST
  slugs:
    - implement-ci-pipeline
  title: Implement CI Pipeline
  type: task
  spec_ref: "@ci-pipeline"
  plan_ref: "@plan-testing-strategy"
  status: completed
  blocked_by: []
  closed_reason: "Merged in PR #2. Added GitHub Actions CI workflow with lint (ruff via
    astral-sh/ruff-action) and test (pytest with CPU-only PyTorch via uv) jobs. Triggers on push to
    main and all PRs. All ACs verified: ac-1 (pytest with CPU torch), ac-2 (ruff check), ac-3 (green
    checks on both jobs)."
  depends_on:
    - "@implement-testing-infrastructure"
  context: []
  priority: 3
  tags: []
  vcs_refs: []
  created_at: 2026-02-11T00:05:30.218Z
  started_at: 2026-02-11T02:20:48.141Z
  completed_at: 2026-02-11T02:27:43.054Z
  notes:
    - _ulid: 01KH508VFBT2H54M5F3RHDF08Z
      created_at: 2026-02-11T00:05:30.219Z
      author: "@claude"
      content: |
        Implementation notes:

        Follow ComfyUI's test-unit.yml pattern: install CPU-only torch via
        --index-url https://download.pytorch.org/whl/cpu, install project deps,
        run pytest. Add ruff for linting. Single ubuntu-latest runner to start
        (extend to matrix later). Add pyproject.toml [tool.ruff] config.
        Files: .github/workflows/test.yml, pyproject.toml (ruff + pytest config)
    - _ulid: 01KH58198P2XYEND6VHT87WAE3
      created_at: 2026-02-11T02:21:10.806Z
      author: "@claude"
      content: "Added .github/workflows/ci.yml with two jobs: lint (ruff via astral-sh/ruff-action) and
        test (pytest with CPU torch via uv). Triggers on push to main and all PRs."
      supersedes: null
  todos: []
  automation: eligible
