{
  "generated_at": "2026-02-14T02:33:57.244Z",
  "branch": "feat/layer-type-filtering",
  "context": {
    "focus": null,
    "threads": [],
    "open_questions": [],
    "updated_at": "2026-02-14T02:33:57.244Z"
  },
  "active_tasks": [],
  "pending_review_tasks": [
    {
      "ref": "01KHA77QE",
      "title": "Add layer-type filtering to block config",
      "started_at": "2026-02-14T02:24:23.423Z",
      "priority": 3,
      "spec_ref": "@layer-type-filter",
      "note_count": 2,
      "last_note_at": "2026-02-14T02:31:51.186Z",
      "todo_count": 0,
      "incomplete_todos": 0
    }
  ],
  "recent_notes": [
    {
      "task_ref": "01KHA77QE",
      "task_title": "Add layer-type filtering to block config",
      "task_status": "pending_review",
      "note_ulid": "01KHCZTZ",
      "created_at": "2026-02-14T02:31:51.186Z",
      "author": "@claude",
      "content": "Implementation complete. Added classify_layer_type function to lib/block_classify.py with architecture-specific patterns (SDXL: attn1/attn2/to_q/to_k/to_v/proj_in/proj_out → attention, ff. → feed_forward, norm → norm; Z-Image: attn.qkv/attn.out/q_norm/k_norm → attention, feed_forward/mlp/w1/w2/w3/fc1/fc2 → feed_forward, norm/ln/rms → norm). Extended make_block_config_node to accept layer_types parameter. Updated SDXL and Z-Image block config nodes with attention/feed_forward/norm sliders. Modified _apply_per_block_lora_strength and _get_block_t_factors to apply layer_type_overrides multiplicatively with block overrides. All 8 ACs covered: ac-1 (classification), ac-2 (LoRA multiplicative), ac-3 (t_factor multiplicative), ac-4 (backwards compatible), ac-5 (UI sliders), ac-6 (None for unmatched), ac-7 (precedence), ac-8 (None for unknown arch). 654 tests pass, ruff clean."
    },
    {
      "task_ref": "01KHCJ41F",
      "task_title": "Implement Full Model Recipe Type",
      "task_status": "completed",
      "note_ulid": "01KHCZ89",
      "created_at": "2026-02-14T02:21:38.421Z",
      "author": "@claude",
      "content": "Implementation complete. Added RecipeModel frozen dataclass with path (str), strength (float, default 1.0), and block_config (BlockConfig or None). Updated RecipeNode type alias and __all__ exports. Added 17 tests covering all 6 ACs: frozen immutability (ac-1), field structure (ac-2), RecipeCompose.with_branch compatibility (ac-3), RecipeMerge target compatibility (ac-4), RecipeNode inclusion (ac-5), no GPU tensors (ac-6). All 613 tests pass, ruff clean."
    },
    {
      "task_ref": "01KHA77Q3",
      "task_title": "Refactor block config from grouped to individual blocks",
      "task_status": "completed",
      "note_ulid": "01KHCYZ5",
      "created_at": "2026-02-14T02:16:40.021Z",
      "author": "@claude",
      "content": "Implementation complete. Refactored from grouped blocks to individual blocks:\n\nSDXL: 7 grouped sliders → 19 individual sliders (IN00-IN08, MID, OUT00-OUT08)\nZ-Image: 8 grouped sliders → 34 individual sliders (L00-L29, NOISE_REF0-1, CTX_REF0-1)\n\nFiles modified:\n- lib/block_classify.py: Updated both classifiers\n- lib/recipe.py: Updated docstring example\n- nodes/block_config_sdxl.py: Updated _SDXL_BLOCKS tuple\n- nodes/block_config_zimage.py: Updated _ZIMAGE_BLOCKS tuple\n- tests/conftest.py: Updated _ZIMAGE_KEYS with numbered refiner submodules\n- tests/test_per_block_control.py: Updated expected block names and counts\n- tests/test_merge_block_config.py: Updated all block name references\n- tests/test_lora_block_strength.py: Updated block config overrides\n- tests/test_block_config.py: Updated example block names\n\nAll 600 tests pass, ruff clean."
    },
    {
      "task_ref": "01KHCRP1",
      "task_title": "Implement: Exit Model Persistence",
      "task_status": "completed",
      "note_ulid": "01KHCSMX",
      "created_at": "2026-02-14T00:43:40.978Z",
      "author": "@claude",
      "content": "## Workflow Embedding\n\nNew input: save_workflow (BOOLEAN, default True). When enabled, embed the ComfyUI workflow JSON in safetensors metadata.\n\nAccess the workflow via HIDDEN inputs in INPUT_TYPES:\n  'hidden': {'prompt': 'PROMPT', 'extra_pnginfo': 'EXTRA_PNGINFO'}\n\nEXTRA_PNGINFO contains the workflow dict. Serialize with json.dumps() into metadata key __ecaj_workflow__. This mirrors how ComfyUI embeds workflow in PNG images via the SaveImage node.\n\nNote: workflow is NOT included in the recipe hash — it's purely informational metadata for reproducibility. Changing the workflow JSON (e.g. rearranging nodes) should not invalidate the cache."
    },
    {
      "task_ref": "01KHCRP1",
      "task_title": "Implement: Exit Model Persistence",
      "task_status": "completed",
      "note_ulid": "01KHCSEZ",
      "created_at": "2026-02-14T00:40:26.534Z",
      "author": "@claude",
      "content": "## Updated: Recipe-in-Metadata Approach\n\nEmbed the full serialized recipe tree in safetensors metadata rather than storing individual fields. The hash is derived FROM the serialized recipe, not computed separately.\n\n### Safetensors Metadata Keys (revised)\n\n- __ecaj_version__: '1'\n- __ecaj_recipe__: JSON-serialized frozen recipe tree (model_patcher replaced with model_path string, all other fields preserved — strengths, t_factors, block_config, tree structure)\n- __ecaj_recipe_hash__: sha256(__ecaj_recipe__) — fast comparison key\n\n### Cache Validation Flow (revised)\n\n1. Read header metadata (fast, no tensor load)\n2. Compare __ecaj_recipe_hash__ against hash of current serialized recipe (fast path)\n3. On hash match → cache hit, load tensors\n4. On mismatch → recompute\n\nThe recipe serialization is deterministic because the tree is frozen dataclasses with tuples. Replace model_patcher with model_path, serialize with json.dumps(sort_keys=True) or deterministic repr().\n\nBenefits: single source of truth, no separate fields to sync, full recipe is inspectable in metadata for debugging, and LoRA file stats (mtime/size) are naturally included since they're part of the recipe tree walk during serialization.\n\nPrevious note about individual __ecaj_lora_stats__, __ecaj_base_model__, __ecaj_block_config__, __ecaj_t_factors__ fields is SUPERSEDED — these are replaced by the single __ecaj_recipe__ field."
    },
    {
      "task_ref": "01KHA77QE",
      "task_title": "Add layer-type filtering to block config",
      "task_status": "pending_review",
      "note_ulid": "01KHA7AP",
      "created_at": "2026-02-13T00:45:02.608Z",
      "author": "@claude",
      "content": "## Implementation Details\n\n### lib/block_classify.py — Add classify_layer_type\n```python\n@functools.lru_cache(maxsize=4096)\ndef classify_layer_type(key: str, arch: str) -> str | None:\n```\n- Strip prefixes (diffusion_model., transformer.)\n- Pattern matching on key segments (order matters — more specific first):\n  - SDXL attention: attn1, attn2, to_q, to_k, to_v, proj_in, proj_out (within blocks)\n  - Z-Image attention: attn.qkv, attn.out, q_norm, k_norm\n  - Feed-forward: ff., mlp., fc1, fc2, .w1., .w2., .w3., feed_forward\n  - Norm: norm, ln, rms\n  - adaLN_modulation → None (conditioning projection, NOT norm)\n  - Return None for: time_embed, label_emb, final_layer, embedders, unclassifiable\n- Add to __all__\n- Precedence: attention > feed_forward > norm\n\n### nodes/block_config.py — Extend make_block_config_node\n```python\ndef make_block_config_node(arch, block_groups, docstring, layer_types=None):\n```\n- When layer_types provided, add FLOAT inputs in INPUT_TYPES (same SLIDER_CONFIG)\n- create_config partitions kwargs into block vs layer-type by checking membership\n- Returns BlockConfig(arch=arch, block_overrides=..., layer_type_overrides=...)\n\n### nodes/block_config_sdxl.py + block_config_zimage.py\n```python\n_LAYER_TYPES = ((\"attention\", \"attention\"), (\"feed_forward\", \"feed_forward\"), (\"norm\", \"norm\"))\n```\nPass as layer_types=_LAYER_TYPES to make_block_config_node.\n\n### lib/per_block.py — Consume layer_type_overrides multiplicatively\n\n_apply_per_block_lora_strength (lines 25-94):\n- Import classify_layer_type\n- Build layer_type_overrides dict alongside block_overrides\n- Per-key: effective = block_s * layer_s\n- Update early-exit has_overrides check\n\n_get_block_t_factors (lines 97-141):\n- Same pattern: effective_t = block_t * layer_t\n- block overrides are absolute t_factor values; layer_type overrides are multipliers\n- layer_type at 1.0 = no change, 0.5 = halve, 2.0 = double\n\n### No changes needed to\nlib/recipe.py (field exists), lib/recipe_eval.py, lib/gpu_ops.py, lib/batch_groups.py\n\n### New tests — tests/test_layer_type_classify.py\n- SDXL: input_blocks.3.1.transformer_blocks.0.attn1.to_q.weight → \"attention\"\n- SDXL: input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight → \"feed_forward\"\n- SDXL: input_blocks.4.0.in_layers.0.weight → \"norm\" (if contains norm)\n- Z-Image: layers.5.attn.qkv.weight → \"attention\"\n- Z-Image: layers.5.feed_forward.w1.weight → \"feed_forward\"\n- Z-Image: layers.5.adaLN_modulation.1.weight → None\n- Unmatched → None; with/without prefixes\n\n### Extend test_per_block_control.py\n- 3 layer_type sliders (attention, feed_forward, norm)\n- create_config stores layer_type_overrides\n- Total inputs = block_sliders + 3\n\n### Extend test_lora_block_strength.py\n- block=0.5, attention=0.7 → effective 0.35\n- attention=0.5 only → 0.5 for attention keys, 1.0 for others\n- Both at 1.0 → no effect\n- layer_type=0.0 → disable that type\n\n### Extend test_merge_block_config.py\n- t_factor with layer_type_overrides grouping\n- block t=0.8, attention=0.5 → effective 0.4\n\n### Key decisions\n- adaLN_modulation → None (SiLU + Linear conditioning projection)\n- q_norm/k_norm → \"attention\" (precedence: attention > feed_forward > norm)\n- proj_in/proj_out in blocks → \"attention\"\n- Unsupported arch or arch=None → None (no error)\n- Negative sliders allowed (ComfyUI permits). No clamping.\n- Zero slider: 0.0 * anything = 0.0 (valid: disable LoRA or passthrough t_factor)\n\n### File-touch checklist\n- [ ] lib/block_classify.py — add classify_layer_type, update __all__\n- [ ] lib/per_block.py — modify both functions\n- [ ] nodes/block_config.py — extend factory\n- [ ] nodes/block_config_sdxl.py — pass _LAYER_TYPES\n- [ ] nodes/block_config_zimage.py — pass _LAYER_TYPES\n- [ ] tests/test_layer_type_classify.py (new)\n- [ ] tests/test_per_block_control.py\n- [ ] tests/test_lora_block_strength.py\n- [ ] tests/test_merge_block_config.py\n\n### Verification\npytest -v && ruff check"
    }
  ],
  "active_todos": [],
  "ready_tasks": [
    {
      "ref": "01KHCJ41G",
      "title": "Implement Model Input Node",
      "priority": 3,
      "spec_ref": "@model-input-node",
      "tags": []
    },
    {
      "ref": "01KHCJ41H",
      "title": "Implement Full Model Loader",
      "priority": 3,
      "spec_ref": "@full-model-loader",
      "tags": []
    }
  ],
  "blocked_tasks": [],
  "recently_completed": [
    {
      "ref": "01KHCJ41F",
      "title": "Implement Full Model Recipe Type",
      "completed_at": "2026-02-14T02:23:52.069Z",
      "closed_reason": "Merged in PR #50. Added RecipeModel frozen dataclass to lib/recipe.py with path (str), strength (float, default 1.0), and block_config (BlockConfig | None) fields. Updated RecipeNode type alias. All 6 ACs covered by 17 tests."
    },
    {
      "ref": "01KHA77Q3",
      "title": "Refactor block config from grouped to individual blocks",
      "completed_at": "2026-02-14T02:19:17.185Z",
      "closed_reason": "Merged in PR #49. Refactored block config from grouped to individual blocks: SDXL 7→19 sliders (IN00-IN08, MID, OUT00-OUT08), Z-Image 8→34 sliders (L00-L29, NOISE_REF0-1, CTX_REF0-1). All 5 ACs covered with tests, CI passing."
    },
    {
      "ref": "01KHCQWY",
      "title": "Fix AC annotation style in test_graph.py",
      "completed_at": "2026-02-14T02:09:31.349Z",
      "closed_reason": "Merged in PR #48. Moved 17 AC annotations from docstring format to standard before-def comment format in test_graph.py. All 6 ACs (@node-graph-testing ac-1 through ac-6) have full test coverage."
    },
    {
      "ref": "01KHCRP1",
      "title": "Implement: Exit Model Persistence",
      "completed_at": "2026-02-14T02:03:37.720Z",
      "closed_reason": null
    },
    {
      "ref": "01KHC3H8",
      "title": "Add full model merging support",
      "completed_at": "2026-02-13T22:32:26.896Z",
      "closed_reason": null
    },
    {
      "ref": "01KHA4D4",
      "title": "Add test for comfyui-packaging ac-3 registry metadata",
      "completed_at": "2026-02-13T05:09:17.859Z",
      "closed_reason": "Added 3 tests for [tool.comfy] metadata in test_packaging.py. PR #46."
    },
    {
      "ref": "01KHA4D1",
      "title": "Add spec coverage for _unpatch_loaded_clones",
      "completed_at": "2026-02-13T04:22:10.603Z",
      "closed_reason": "PR #44 merged. Added ac-7 to @exit-patch-install and annotated 5 tests."
    },
    {
      "ref": "01KHA4CV",
      "title": "Fill missing AC annotations in tests",
      "completed_at": "2026-02-13T01:01:47.213Z",
      "closed_reason": "Fixed AC annotations in 3 files: added # AC comments to test_lora_block_strength.py (14 tests), corrected wrong refs in test_recipe.py (3 classes), converted hybrid docstring format in test_compile_plan.py (13 tests). 67 tests pass, ruff clean."
    },
    {
      "ref": "01KHA4CQ",
      "title": "Delete docs/design.md",
      "completed_at": "2026-02-13T00:58:35.578Z",
      "closed_reason": "Deleted docs/design.md, removed references from AGENTS.md, removed empty docs/ directory"
    },
    {
      "ref": "01KH5XN3",
      "title": "Add strict mode for batched catch-all fallbacks in widen.py",
      "completed_at": "2026-02-12T23:15:19.865Z",
      "closed_reason": null
    }
  ],
  "recent_commits": [
    {
      "hash": "f1a83f4",
      "full_hash": "f1a83f41caf6a05e5b23edeb73ffdb7f2c4e9b15",
      "date": "2026-02-14T02:32:46.000Z",
      "message": "feat: add layer-type filtering to block config",
      "author": "Jacob Chapel"
    },
    {
      "hash": "20f5376",
      "full_hash": "20f5376b5f12e8334a2bf374d3c180c7b2607a14",
      "date": "2026-02-14T02:23:41.000Z",
      "message": "Merge pull request #50 from chapel/feat/recipe-model-type",
      "author": "Jacob Chapel"
    },
    {
      "hash": "e834850",
      "full_hash": "e8348500854c977473168d37daa4cb0f7d145a33",
      "date": "2026-02-14T02:21:54.000Z",
      "message": "feat: add RecipeModel type for full model merging",
      "author": "Jacob Chapel"
    },
    {
      "hash": "ae42314",
      "full_hash": "ae42314987988d215867f11c7b1277272bc40de7",
      "date": "2026-02-14T02:19:07.000Z",
      "message": "Merge pull request #49 from chapel/refactor/individual-block-control",
      "author": "Jacob Chapel"
    },
    {
      "hash": "265f767",
      "full_hash": "265f7673cb9fb619c23ed63cce50872d3380d21c",
      "date": "2026-02-14T02:17:00.000Z",
      "message": "refactor: change block config from grouped to individual blocks",
      "author": "Jacob Chapel"
    },
    {
      "hash": "01ea19a",
      "full_hash": "01ea19a7edf97595347cdf8ae7a952f107582d46",
      "date": "2026-02-14T02:09:24.000Z",
      "message": "Merge pull request #48 from chapel/style/ac-annotation-test-graph",
      "author": "Jacob Chapel"
    },
    {
      "hash": "7e9dbfb",
      "full_hash": "7e9dbfbcd6658fe783266addf038f90c6e93268b",
      "date": "2026-02-14T02:07:35.000Z",
      "message": "style: move AC annotations to before-def placement in test_graph.py",
      "author": "Jacob Chapel"
    },
    {
      "hash": "ec98f47",
      "full_hash": "ec98f4704ea1bf4f78b000f8909c8f11d38d28d1",
      "date": "2026-02-14T01:56:53.000Z",
      "message": "Merge pull request #47 from chapel/feat/exit-model-persistence",
      "author": "Jacob Chapel"
    },
    {
      "hash": "93b985f",
      "full_hash": "93b985f417b76a5294895f44bb225c2d61dbe394",
      "date": "2026-02-14T01:46:42.000Z",
      "message": "fix: address PR review feedback",
      "author": "Jacob Chapel"
    },
    {
      "hash": "9f7c4e6",
      "full_hash": "9f7c4e64caa1af177203a713bc1590dd88dfafee",
      "date": "2026-02-14T01:29:32.000Z",
      "message": "feat: add exit node model persistence (save/cache merged models)",
      "author": "Jacob Chapel"
    }
  ],
  "working_tree": {
    "clean": true,
    "staged": [],
    "unstaged": [],
    "untracked": []
  },
  "inbox_items": [
    {
      "ref": "01KHCXS4",
      "text": "Recipe serialization as a trait/protocol — serialize_recipe currently uses isinstance checks for each recipe type. Should be a protocol method on RecipeNode so new recipe types implement their own serialization. Prevents silent skips and keeps persistence.py decoupled from recipe type enumeration.",
      "created_at": "2026-02-14T01:55:53.531Z",
      "tags": [],
      "added_by": "@claude"
    },
    {
      "ref": "01KHCXS7",
      "text": "compute_lora_stats._walk() silently ignores unknown recipe node types — should raise ValueError like serialize_recipe does. Related to serialization-as-trait refactor.",
      "created_at": "2026-02-14T01:55:56.494Z",
      "tags": [],
      "added_by": "@claude"
    },
    {
      "ref": "01KHCXS9",
      "text": "load_affected_keys should wrap safetensors errors with helpful message pointing to cached file corruption — tells users to delete and re-run.",
      "created_at": "2026-02-14T01:55:58.446Z",
      "tags": [],
      "added_by": "@claude"
    }
  ],
  "stats": {
    "total_tasks": 67,
    "in_progress": 0,
    "pending_review": 1,
    "ready": 4,
    "blocked": 0,
    "completed": 60,
    "inbox_items": 3
  }
}