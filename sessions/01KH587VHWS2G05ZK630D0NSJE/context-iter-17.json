{
  "generated_at": "2026-02-11T04:18:46.360Z",
  "branch": "feat/block-config-type",
  "context": {
    "focus": null,
    "threads": [],
    "open_questions": [],
    "updated_at": "2026-02-11T04:18:46.360Z"
  },
  "active_tasks": [],
  "pending_review_tasks": [
    {
      "ref": "01KH4HA48P",
      "title": "Implement Block Config Type",
      "started_at": "2026-02-11T04:15:55.148Z",
      "priority": 3,
      "spec_ref": "@block-config-type",
      "note_count": 2,
      "last_note_at": "2026-02-11T04:17:41.947Z",
      "todo_count": 0,
      "incomplete_todos": 0
    }
  ],
  "recent_notes": [
    {
      "task_ref": "01KH4HA48P",
      "task_title": "Implement Block Config Type",
      "task_status": "pending_review",
      "note_ulid": "01KH5EPM",
      "created_at": "2026-02-11T04:17:41.947Z",
      "author": "@claude",
      "content": "Implemented BlockConfig frozen dataclass with arch, block_overrides (tuple of (pattern, float) pairs), and layer_type_overrides fields. Added block_config: object = None field to RecipeLoRA and RecipeMerge for backwards compatibility. AC-1: BlockConfig is frozen, stores arch and per-block float values as tuple of pairs. AC-2: RecipeLoRA and RecipeMerge accept BlockConfig or None. Created tests/test_block_config.py with 22 tests covering all ACs. 374 total tests pass, ruff clean."
    },
    {
      "task_ref": "01KH4HA486",
      "task_title": "Implement Memory Management",
      "task_status": "completed",
      "note_ulid": "01KH5EBD",
      "created_at": "2026-02-11T04:11:34.092Z",
      "author": "@claude",
      "content": "Implemented GPU memory management with all 5 ACs covered. Added gc.collect() and torch.cuda.empty_cache() calls per-chunk in lib/executor.py:chunked_evaluation (AC-1) and between OpSignature groups in nodes/exit.py:execute (AC-2). Verified existing loader cleanup pattern frees delta caches (AC-3). Verified install_merged_patches ensures CPU-only patches with correct dtype (AC-4). compute_batch_size already provides conservative batch sizing within VRAM bounds (AC-5). Created tests/test_memory_management.py with 20 tests covering all ACs. 352 total tests pass, ruff clean."
    },
    {
      "task_ref": "01KH4HA47Z",
      "task_title": "Implement Z-Image LoRA Loader",
      "task_status": "completed",
      "note_ulid": "01KH5DZ7",
      "created_at": "2026-02-11T04:04:55.048Z",
      "author": "@claude",
      "content": "Implemented Z-Image LoRA Loader with complete @zimage-loader AC coverage. Added DeltaSpec.offset field for QKV slice indexing (AC-3). Enhanced _parse_zimage_lora_key() to handle Diffusers key patterns including transformer./diffusion_model. prefixes, LyCORIS format with lycoris_ prefix, and to_out.0→out mapping (AC-2). QKV keys now fuse into single qkv.weight with proper offset tuples: q=(0,3840), k=(3840,3840), v=(7680,3840) (AC-1). Added _normalize_lycoris_key() for underscore→dot conversion preserving compound names. Created tests/test_zimage_loader.py with 20 tests covering all 3 ACs. All 332 tests pass, ruff clean."
    },
    {
      "task_ref": "01KH4HA47S",
      "task_title": "Implement SDXL LoRA Loader",
      "task_status": "completed",
      "note_ulid": "01KH5DHA",
      "created_at": "2026-02-11T03:57:18.976Z",
      "author": "@claude",
      "content": "Fixed SDXL key parsing algorithm. The original implementation naively split all underscores into dots, breaking compound identifiers like input_blocks, transformer_blocks, proj_in, proj_out, to_q, to_k, to_v. Implemented _tokenize_lora_path() with greedy matching for 16 known compound tokens. Added 21 tests in test_sdxl_loader.py covering all 3 ACs: AC-1 (block type mapping for input_blocks/middle_block/output_blocks), AC-2 (DeltaSpec contents: kind, up/down factors, rank, scale), AC-3 (attention key mapping: proj_in, proj_out, to_q/to_k/to_v/to_out). All 312 tests pass, ruff clean."
    },
    {
      "task_ref": "01KH4HA46H",
      "task_title": "Implement Exit Node",
      "task_status": "completed",
      "note_ulid": "01KH5D0Y",
      "created_at": "2026-02-11T03:48:22.468Z",
      "author": "@claude",
      "content": "Implemented WIDENExitNode.execute() in nodes/exit.py. Added _validate_recipe_tree() for AC-2 (validates tree structure, raises ValueError with position on type mismatches). execute() orchestrates: (1) analyze_recipe for LoRA loading and set_affected map (AC-1), (2) compile_batch_groups for OpSignature grouping, (3) chunked_evaluation with evaluate_recipe as eval_fn for batched GPU evaluation (AC-3,4,5), (4) install_merged_patches for set patch installation (AC-7,8). Updated lib/executor.py evaluate_recipe to handle single-branch RecipeCompose as filter_delta not merge_weights (AC-6). Added 22 tests in tests/test_exit_node.py covering all 8 ACs. All 291 tests pass, ruff clean."
    },
    {
      "task_ref": "01KH4HA48P",
      "task_title": "Implement Block Config Type",
      "task_status": "pending_review",
      "note_ulid": "01KH4HA4",
      "created_at": "2026-02-10T19:44:03.350Z",
      "author": "@claude",
      "content": "Implementation notes:\n\nAdd to lib/recipe.py: @dataclass(frozen=True) class BlockConfig with fields\narch (str), block_overrides (tuple), layer_type_overrides (tuple). The\nblock_overrides is a tuple of (block_pattern, value) pairs e.g.,\n((\"IN00-02\", 0.5), (\"MID\", 1.0), ...). The layer_type_overrides is a tuple\nof (layer_type, value) pairs for cross-cutting layer type control (attention,\nfeed_forward, norm, etc.). Add block_config: object = None field to both\nRecipeLoRA and RecipeMerge -- since frozen, this means defining new versions\nwith the additional field. Field defaults to None for backwards compat. The\narch field must match RecipeBase.arch -- validated at Exit time.\nFiles: lib/recipe.py.\n"
    }
  ],
  "active_todos": [],
  "ready_tasks": [
    {
      "ref": "01KH508VE1",
      "title": "Implement ComfyUI Mocking and Fixtures",
      "priority": 3,
      "spec_ref": "@comfyui-mocking",
      "tags": []
    }
  ],
  "blocked_tasks": [],
  "recently_completed": [
    {
      "ref": "01KH4HA486",
      "title": "Implement Memory Management",
      "completed_at": "2026-02-11T04:15:06.700Z",
      "closed_reason": "Merged in PR #17. Implemented GPU memory management with gc.collect() and torch.cuda.empty_cache() calls per-chunk and between OpSignature groups. Loader cleanup in finally block frees delta caches. All 5 ACs covered with 20 tests in test_memory_management.py."
    },
    {
      "ref": "01KH4HA47Z",
      "title": "Implement Z-Image LoRA Loader",
      "completed_at": "2026-02-11T04:07:39.216Z",
      "closed_reason": "Merged in PR #16. Implemented Z-Image LoRA Loader with QKV fusing - separate to_q/to_k/to_v keys fuse to attention.qkv.weight (AC-1), Diffusers key names map to S3-DiT parameters including LyCORIS format (AC-2), QKV DeltaSpecs have offset indexing q=(0,3840), k=(3840,3840), v=(7680,3840) (AC-3). 20 tests covering all 3 ACs."
    },
    {
      "ref": "01KH4HA47S",
      "title": "Implement SDXL LoRA Loader",
      "completed_at": "2026-02-11T03:59:43.634Z",
      "closed_reason": "Merged in PR #15. Implemented SDXL LoRA Loader with greedy token matching for compound identifiers (input_blocks, proj_in, to_q, etc.). Added 21 tests covering all 3 ACs: block type mapping, DeltaSpec contents, and attention key mapping."
    },
    {
      "ref": "01KH4HA46H",
      "title": "Implement Exit Node",
      "completed_at": "2026-02-11T03:52:01.713Z",
      "closed_reason": "Merged in PR #14. Implemented WIDENExitNode.execute() orchestrating the complete recipe tree evaluation with _validate_recipe_tree() for tree structure validation. All 8 ACs covered: returns MODEL with set patches (AC-1), validates tree with position-aware errors (AC-2), compose targets call merge_weights (AC-3), single LoRA targets call filter_delta (AC-4), chained merges evaluate inner first (AC-5), single-branch compose uses filter_delta (AC-6), downstream LoRA patches apply additively (AC-7), patch tensors match base model dtype (AC-8). 22 tests added in test_exit_node.py, 291 total tests passing."
    },
    {
      "ref": "01KH4HA46X",
      "title": "Implement Exit Batched Evaluation",
      "completed_at": "2026-02-11T03:42:23.167Z",
      "closed_reason": "Merged in PR #13. Implemented evaluate_recipe() tree walker in lib/executor.py with full AC coverage: RecipeCompose→merge_weights_batched (AC-1), RecipeLoRA→filter_delta_batched (AC-2), chained RecipeMerge→recursive evaluation (AC-3), results stay on GPU (AC-4), backbone override passed to WIDEN (AC-5). 13 tests added covering all 5 ACs."
    },
    {
      "ref": "01KH4HA46P",
      "title": "Implement Exit Recipe Analysis",
      "completed_at": "2026-02-11T03:35:17.741Z",
      "closed_reason": "Merged in PR #12. Implemented exit recipe analysis in lib/analysis.py with all 6 ACs covered: tree walk to RecipeBase (AC-1), object identity-based set ID assignment (AC-2), architecture loader selection (AC-3), affected-key map tracking (AC-4), key filtering for processing (AC-5), and FileNotFoundError with context (AC-6). 22 tests verify all acceptance criteria."
    },
    {
      "ref": "01KH4HA47M",
      "title": "Implement Architecture-Specific LoRA Loaders",
      "completed_at": "2026-02-11T03:26:45.215Z",
      "closed_reason": "Merged in PR #11. Implemented architecture-specific LoRA loaders with pluggable registry design. Created LoRALoader ABC in lib/lora/base.py with load(), affected_keys, get_delta_specs(), cleanup() interface. Implemented SDXLLoader for kohya/A1111 format and ZImageLoader with QKV fusing support. All 4 ACs covered with 21 tests: AC-1 (architecture selection/key mapping), AC-2 (DeltaSpec production), AC-3 (pluggable design), AC-4 (interface contract)."
    },
    {
      "ref": "01KH4HA47F",
      "title": "Implement Batched Pipeline Executor",
      "completed_at": "2026-02-11T03:18:03.688Z",
      "closed_reason": "Merged in PR #10. Implemented batched pipeline executor primitives: OpSignature (parameter grouping), DeltaSpec (LoRA delta specs), compile_batch_groups (shape/affecting_sets grouping), compute_batch_size (70% VRAM targeting), apply_lora_batch_gpu (torch.bmm for standard LoRA, torch.kron for LoKr), and chunked_evaluation (OOM backoff wrapper). All 7 ACs covered by 30 tests."
    },
    {
      "ref": "01KH4HA473",
      "title": "Implement Exit Patch Installation",
      "completed_at": "2026-02-11T03:10:24.420Z",
      "closed_reason": "Merged in PR #9. Implemented install_merged_patches() helper with ModelPatcher cloning, diffusion_model. key prefixing, CPU transfer, and base dtype matching. Added IS_CHANGED classmethod using SHA-256 hash of LoRA file (path, mtime, size) tuples for cache invalidation. All 6 acceptance criteria covered by 26 tests."
    },
    {
      "ref": "01KH4HA46D",
      "title": "Implement Merge Node",
      "completed_at": "2026-02-11T03:04:40.091Z",
      "closed_reason": "Merged in PR #8. Implemented Merge node with base/target type validation. merge() validates base is RecipeBase or RecipeMerge (rejects RecipeLoRA/RecipeCompose with helpful error message suggesting Entry node or Merge output). All 6 ACs covered by 23 tests: AC-1 (RecipeMerge with fields), AC-2 (no backbone defaults None), AC-3 (backbone stored), AC-4 (merge chaining), AC-5 (invalid base rejection), AC-6 (t_factor -1.0 preserved). All tests pass, ruff clean."
    }
  ],
  "recent_commits": [
    {
      "hash": "717394d",
      "full_hash": "717394d99f93807e84724b0005eeb35208db0036",
      "date": "2026-02-11T04:17:49.000Z",
      "message": "feat: implement BlockConfig type for per-block weight configuration",
      "author": "Jacob Chapel"
    },
    {
      "hash": "714cef4",
      "full_hash": "714cef4231194a83117d6fcc78a5ae4858c47f67",
      "date": "2026-02-11T04:14:57.000Z",
      "message": "Merge pull request #17 from chapel/feat/memory-management",
      "author": "Jacob Chapel"
    },
    {
      "hash": "f6659a3",
      "full_hash": "f6659a315b0af1e5b90b310550205a297e5dae6e",
      "date": "2026-02-11T04:11:49.000Z",
      "message": "feat: implement GPU memory management with gc.collect and empty_cache",
      "author": "Jacob Chapel"
    },
    {
      "hash": "ce28a6d",
      "full_hash": "ce28a6dea3343cc34ea694e5981e49de556a28f3",
      "date": "2026-02-11T04:07:29.000Z",
      "message": "Merge pull request #16 from chapel/feat/zimage-lora-loader",
      "author": "Jacob Chapel"
    },
    {
      "hash": "9ad5ad9",
      "full_hash": "9ad5ad9c57b6a57fc0f38b17cb84dbb2abc81044",
      "date": "2026-02-11T04:05:14.000Z",
      "message": "feat: implement Z-Image LoRA Loader with QKV fusing and offset indexing",
      "author": "Jacob Chapel"
    },
    {
      "hash": "88dbd15",
      "full_hash": "88dbd15c26cb0e016c4caaaa76d9b70e7d7e9af6",
      "date": "2026-02-11T03:59:32.000Z",
      "message": "Merge pull request #15 from chapel/feat/sdxl-lora-loader",
      "author": "Jacob Chapel"
    },
    {
      "hash": "2ecbad4",
      "full_hash": "2ecbad4a7fbfa6acd386d991cf7e6d9cf851a5a2",
      "date": "2026-02-11T03:57:29.000Z",
      "message": "feat: fix SDXL LoRA key parsing and add comprehensive tests",
      "author": "Jacob Chapel"
    },
    {
      "hash": "182fe18",
      "full_hash": "182fe187e61d59661f35c80583d4d362a142d433",
      "date": "2026-02-11T03:51:52.000Z",
      "message": "Merge pull request #14 from chapel/feat/exit-batched-eval",
      "author": "Jacob Chapel"
    },
    {
      "hash": "e6ffa2f",
      "full_hash": "e6ffa2fada0d9da0a261b049d0cc3a69d303837d",
      "date": "2026-02-11T03:48:42.000Z",
      "message": "feat: implement WIDEN Exit Node with full batched GPU pipeline",
      "author": "Jacob Chapel"
    },
    {
      "hash": "b4304b4",
      "full_hash": "b4304b46db4b0385babd85361cae0aec64caa1ea",
      "date": "2026-02-11T03:42:09.000Z",
      "message": "Merge pull request #13 from chapel/feat/exit-batched-eval",
      "author": "Jacob Chapel"
    }
  ],
  "working_tree": {
    "clean": false,
    "staged": [],
    "unstaged": [],
    "untracked": [
      "uv.lock"
    ]
  },
  "inbox_items": [],
  "stats": {
    "total_tasks": 25,
    "in_progress": 0,
    "pending_review": 1,
    "ready": 1,
    "blocked": 0,
    "completed": 19,
    "inbox_items": 0
  }
}