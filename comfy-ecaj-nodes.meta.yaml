kynetic_meta: "1.0"
agents:
  - _ulid: 01KH4D20YRV8MXAEMAC70AKQQZ
    id: claude
    name: Claude Code Agent
    description: Primary development agent for this project.
    capabilities:
      - code
      - test
      - refactor
      - review
    tools:
      - kspec
      - git
      - uv
    conventions: []
workflows:
  - _ulid: 01KH4D2G8XEYKRQNNZR9HC6S8A
    id: task-work-session
    trigger: manual
    description: Core pattern for working on a task. Full lifecycle from start through PR merge.
    steps:
      - type: check
        content: |-
          Check for existing in_progress or pending_review tasks.
          Use: kspec session start (shows active work first)
          Priority: pending_review > in_progress > ready
        on_fail: Inherit existing work instead of starting new.
      - type: action
        content: |-
          Choose task to work on.
          Use: kspec tasks ready to see available tasks
      - type: check
        content: |-
          Verify work is not already done.
          Check git history and existing code.
        on_fail: Mark task complete with Already implemented reason
      - type: action
        content: |-
          Start the task.
          Use: kspec task start @task
      - type: action
        content: |-
          Work on the task, adding notes as you go.
          Use: kspec task note @task "What you are doing..."
      - type: check
        content: All changes committed
        on_fail: "Commit changes with Task: @task trailer."
      - type: action
        content: |-
          Submit task for review.
          Use: kspec task submit @task
      - type: action
        content: |-
          Create PR.
          Use: /pr skill or gh pr create
  - _ulid: 01KH4D2XWDYBF7V5FW6GA497JC
    id: session-reflect
    trigger: session-end
    description: Structured reflection after work sessions. Surfaces learnings, identifies friction, and
      captures improvements.
    steps:
      - type: action
        content: |-
          Identify what worked well this session.
          Be specific. Consider: workflows, tools, communication, decisions.
      - type: action
        content: |-
          Identify friction points - where things were harder than needed.
          Focus on systemic issues, not one-off mistakes.
      - type: action
        content: |-
          Check if friction points are already tracked.
          Search specs, tasks, AND inbox before proposing new improvements.
      - type: action
        content: |-
          For untracked friction, propose concrete improvements.
          Include: what it would do, how it helps, rough scope.
      - type: decision
        content: Present findings to user - ask about each improvement one at a time
        options:
          - Worth capturing -> proceed to capture
          - Needs refinement -> discuss and refine
          - Not worth it -> skip
          - Done with reflection -> complete workflow
      - type: action
        content: |-
          Capture approved items:
          - Actionable improvements: kspec inbox add
          - Friction patterns: kspec meta observe friction
          - Success patterns: kspec meta observe success
          - Open questions: kspec meta question add
  - _ulid: 01KH4D3C8G9G78XHVVJXB0B874
    id: pr-review-merge
    trigger: pr-merge
    description: Quality gate for reviewing and merging PRs. Ensures all CI passes, reviews addressed,
      and threads resolved before merge.
    steps:
      - type: check
        content: All CI checks complete (none pending or running)
        on_fail: Wait for CI to finish. Do not merge while checks are running.
      - type: check
        content: All CI checks pass (green)
        on_fail: Fix failures, push changes, wait for CI to re-run and pass.
      - type: action
        content: |-
          Read ALL review comments on the PR.
          Use: gh pr view --comments or GitHub UI
      - type: check
        content: All review feedback addressed
        on_fail: Fix each issue raised by reviewers. Push changes and wait for re-review if needed.
      - type: action
        content: |-
          Check for @claude mentions or other requests in comments.
          Complete any actions the PR agent could not.
      - type: check
        content: All requested actions completed
        on_fail: Complete the actions yourself before proceeding.
      - type: check
        content: All review threads resolved in GitHub UI
        on_fail: Click Resolve conversation on each thread after addressing.
      - type: decision
        content: Ready to merge?
        options:
          - Yes - all checks green, all reviews addressed, all threads resolved
          - No - need user approval to merge with known issues
          - Skip - user explicitly said to merge anyway
      - type: action
        content: |-
          Merge the PR.
          Use: gh pr merge (prefer merge commit to preserve trailers)
  - _ulid: 01KH4D3QHJSWS40QETS1K5ER2N
    id: inbox-triage
    trigger: session-start
    description: Systematic processing of inbox items into specs and tasks.
    steps:
      - type: action
        content: |-
          Get context and list inbox items.
          Use: kspec session start --full
          Use: kspec inbox list
      - type: action
        content: |-
          Categorize items by type:
          - Bugs
          - Spec gaps
          - Quick wins
          - Larger features (need plan mode)
          - Delete candidates
      - type: decision
        content: Process each item - is it still relevant?
        options:
          - No -> delete it
          - Yes, spec exists -> promote to task
          - Yes, need spec -> create spec first
          - Unclear -> leave for later
      - type: action
        content: |-
          For behavior changes, follow spec-first approach:
          1. Check if spec covers the change
          2. Create or update spec with AC if needed
          3. Derive task or promote inbox item
  - _ulid: 01KH4D44TWNR22J821DBRS9YPV
    id: local-review
    trigger: manual
    description: Quality enforcement for pre-PR review. Verifies AC coverage with annotations, test
      quality, and test isolation.
    steps:
      - type: action
        content: |-
          Get spec reference and read acceptance criteria.
          Use: kspec item get @spec to see ACs
          Each AC needs test coverage.
      - type: check
        content: |-
          Every AC has test coverage with AC annotation.
          Search tests for: # AC: @spec-ref ac-N
        on_fail: "MUST-FIX: Missing AC coverage is a blocking issue."
      - type: check
        content: |-
          All tests validate real behavior (no fluff tests).
          Tests should fail if the feature breaks.
        on_fail: "MUST-FIX: Identify and flag fluff tests."
      - type: check
        content: |-
          Tests are properly isolated.
          No shared mutable state across tests.
          Fresh fixtures for each test case.
        on_fail: "MUST-FIX: Tests must be properly isolated."
      - type: action
        content: |-
          Report findings.
          List all MUST-FIX issues that block PR creation.
          Non-blocking suggestions can be noted separately.
  - _ulid: 01KH4D4MGKTBM16W1NFT9TMQJS
    id: pr-review-loop
    trigger: loop-pr-review
    description: PR review subagent workflow for loop mode. Runs local review, verifies AC coverage and
      spec alignment, fixes issues, waits for CI, and merges with quality gates.
    steps:
      - type: action
        content: |-
          Run local review workflow first.
          Use: /local-review skill
      - type: check
        content: |-
          Verify all spec ACs linked to task have test coverage.
          Check test files for AC annotations.
        on_fail: Add missing test coverage before continuing.
      - type: check
        content: |-
          Verify implementation matches spec requirements.
          Read spec, read implementation, compare.
        on_fail: Fix misalignment between spec and implementation.
      - type: decision
        content: Evaluate local-review findings.
        options:
          - MUST-FIX issues, can fix -> Fix and continue
          - MUST-FIX issues, cannot fix -> Mark needs_review, EXIT
          - Only advisory issues -> Continue with merge
          - No issues -> Continue with merge
      - type: action
        content: Push changes (if any fixes were made).
      - type: check
        content: |-
          Wait for CI to complete and pass.
          CRITICAL: Re-verify CI after ANY push.
        on_fail: "If CI fails: investigate, fix, push, return to this step."
      - type: action
        content: |-
          Post review summary as PR comment.
          Use: gh pr comment
      - type: action
        content: |-
          Follow PR review merge gates.
          Use: kspec workflow start @pr-review-merge
      - type: check
        content: Verify PR was successfully merged.
        on_fail: Check for conflicts or protection rules.
      - type: action
        content: |-
          Mark task completed with PR reference.
          Use: kspec task complete @task --reason "Merged in PR #N"
  - _ulid: 01KH4W1R540NJ1MYZ1XAM9D7KR
    id: spec-plan-design
    trigger: manual
    description: Research and design phase for plan-to-spec translation. Explore codebase, clarify
      requirements, design approach, review for completeness and spec gaps. Concludes with choosing
      import or manual execution path.
    steps:
      - type: action
        content: >-
          Explore and research the codebase.


          Understand: existing specs/items in the domain, related patterns, current code structure,
          traits that may apply.


          Use /spec skill knowledge for spec types, AC format, and trait reference.


          Focus on what already exists to avoid duplication. Use parallel searches for efficiency.
        inputs:
          - name: feature_description
            description: What you are planning to build
            type: string
      - type: action
        content: >-
          Clarify requirements with the user.


          Present structured questions with clear options. One question at a time - do not batch
          multiple questions.


          Each question should resolve a specific design choice or scope decision.


          Continue until no open questions remain. Capture answers as they inform the design.
      - type: action
        content: >-
          Design the approach.


          Synthesize exploration findings, user answers, and requirements into a concrete design.


          Propose: spec items needed, AC for each, applicable traits, parent placement, and task
          structure.


          Write the design to a durable artifact (plan file or document) so it survives session
          boundaries.
      - type: check
        content: Design passes holistic review
        on_fail: >-
          Address review feedback - fix gaps, refine AC, add missing traits. Iterate until review
          passes.


          Review for: (1) completeness - gaps or missing scenarios, (2) consistency - specs align
          with existing patterns, (3) spec coverage - proper types, AC quality, trait applicability
          per /spec skill, (4) edge cases.


          Exit criteria: design written to file, all review issues addressed.
      - type: decision
        content: Choose execution path based on the reviewed plan
        options:
          - Import path - write structured plan document and auto-generate (3+ specs, batch creation)
          - Manual path - create specs incrementally with kspec commands (1-2 specs, quick additions)
  - _ulid: 01KH4W2EVRR14Z55XSGY646P3C
    id: spec-plan-import
    trigger: manual
    description: Execute plan via structured document import - write document, choose module, preview,
      import, review traits, validate, start work. Follows @spec-plan-design. Import auto-creates
      plan record with status active.
    steps:
      - type: action
        content: >-
          Write or finalize plan document.


          Format: # Title, ## Specs with YAML code block (title required, optional: slug, type,
          parent, AC, traits),

          ## Tasks with derive_from_specs flag, ## Implementation Notes (plain text).
        inputs:
          - name: plan_file_path
            description: Path to the markdown plan file
            type: string
      - type: action
        content: >-
          Choose target module.


          Use: kspec item list --type module


          If no suitable module exists, create one: kspec item add --type module --title "Module
          Name"


          Note the generated reference for the next step.
        inputs:
          - name: module_ref
            description: Reference to the target module
            type: ref
      - type: action
        content: |-
          Preview with dry-run.
          Use: kspec plan import <path> --module @module --dry-run
          Review: spec count, task count, errors, skipped items.
      - type: check
        content: Dry-run output acceptable - all specs valid, parents resolved, no circular deps, at least
          one spec found
        on_fail: |-
          Fix document based on error type:
          (1) YAML parse errors - fix syntax
          (2) Missing parent refs - add parent to plan or verify existing ref
          (3) Circular deps - restructure parent chain
          (4) Missing required fields - add title to spec entries
          Re-run dry-run.
      - type: action
        content: >-
          Run actual import.


          Use: kspec plan import <path> --module @module


          For re-imports of revised documents, add --update to update existing specs.


          Import auto-creates plan record (status: active) with derived_specs and derived_tasks
          linked.


          Verify: kspec plan get @plan-slug
      - type: action
        content: >-
          Review and apply traits.


          Use: kspec trait list for available traits.


          For each created spec, consider cross-cutting concerns (json-output, dry-run,
          error-guidance, semantic-exit-codes, shadow-commit, filterable-list).


          Apply any not already declared in plan document: kspec item trait add @spec @trait


          Note: traits add inherited AC automatically.
      - type: check
        content: Validate references - kspec validate --refs
        on_fail: Fix reference issues (dangling parent refs, missing spec_ref/plan_ref links)
      - type: action
        content: |-
          Start implementation.
          Pick first task from: kspec plan get @plan --json (derived_tasks).
          Use: kspec task start @task
          Then follow /task-work for task lifecycle.
  - _ulid: 01KH4W30QQFDJS6WF58B47PB0J
    id: spec-plan-manual
    trigger: manual
    description: Execute plan via incremental spec creation - create plan record, find parent, create
      specs with AC, review traits, derive tasks with plan linking, validate, start work. Follows
      @spec-plan-design.
    steps:
      - type: action
        content: >-
          Create plan record.


          Use: kspec plan add --title "Plan Title" --content "Brief description of what is being
          planned" --status approved


          Status approved because you are committing to the work.
        inputs:
          - name: plan_ref
            description: The created plan reference
            type: ref
      - type: action
        content: >-
          Find parent and create spec items.


          Search: kspec search "<keyword>", kspec item list --tag <domain>, kspec item get @parent


          If no suitable parent exists, create a module: kspec item add --type module --title
          "Module Name"


          Create specs: kspec item add --under @parent --title "Title" --type feature --slug slug


          Repeat for each spec.
        inputs:
          - name: parent_ref
            description: Reference to the parent item
            type: ref
      - type: action
        content: >-
          Add acceptance criteria.


          For each spec: kspec item ac add @spec --given "precondition" --when "action" --then
          "expected result"


          Each AC independently testable. 3-5 AC per spec is typical.


          Cover happy path and key edge cases.
      - type: action
        content: |-
          Review and apply traits.
          Use: kspec trait list to browse available traits.
          Consider cross-cutting concerns for the spec type.
          Apply: kspec item trait add @spec @trait
          Traits add inherited AC automatically.
      - type: action
        content: >-
          Derive tasks and link to plan.


          Preview: kspec derive @spec --dry-run


          Create: kspec derive @spec (recursive by default, creates task tree with dependencies)


          Link each derived task to plan: kspec task set @task --plan-ref @plan


          Set plan active: kspec plan set @plan --status active


          Add implementation notes: kspec task note @task "Implementation approach: ..."


          Note: task set --plan-ref creates a one-way link (task->plan). The plan derived_tasks
          array is only auto-updated by kspec plan derive and kspec plan import, not by manual
          linking.
      - type: check
        content: Validate all references - kspec validate --refs. Verify spec_ref and plan_ref resolve
          correctly on tasks.
        on_fail: Fix reference issues
      - type: action
        content: >-
          Verify structure.


          kspec item status @spec shows linked tasks.


          For each task: kspec task get @task confirms plan_ref and spec_ref are set.


          Note: check task-side links (not plan derived_tasks which is not auto-updated in manual
          path).
      - type: action
        content: |-
          Start implementation.
          Use: kspec task start @first-task
          Then follow /task-work for task lifecycle.
  - _ulid: 01KH53VJMS1TPSTYMWCPHJZMTR
    id: session-start
    trigger: session-start
    description: Get context at the beginning of a work session.
    steps:
      - type: action
        content: Run kspec session start to get context
      - type: check
        content: Are there active (in_progress) tasks?
        on_fail: Pick from ready tasks or triage inbox
      - type: action
        content: Review ready tasks and inbox items
      - type: action
        content: Start work on chosen task via kspec task start
  - _ulid: 01KH53VMGSZYW2QG2PQW7PWN99
    id: task-lifecycle
    trigger: task-complete
    description: Complete a task properly with notes and cleanup.
    steps:
      - type: action
        content: Add completion note describing what was done
      - type: action
        content: Run kspec task complete @task --reason "summary"
      - type: check
        content: Are there uncommitted changes?
        on_fail: Commit changes with descriptive message
      - type: action
        content: Review if task unblocked other work
  - _ulid: 01KH53VPSMRZ2H3B3A4F2YXWD0
    id: codebase-audit
    trigger: pre-release
    description: "Comprehensive codebase audit for release readiness. Five-phase workflow: parallel
      exploration (docs, code, config, tests, specs), compilation by severity, interactive triage,
      execution, and summary."
    steps: []
  - _ulid: 01KH53VRVYAGYWHA6SMMSZP251
    id: spec-first
    trigger: behavior-change
    description: "Check spec coverage before implementing changes. Core principle: If changing behavior
      and spec doesn't cover it, update the spec first."
    steps:
      - type: check
        content: Does the spec cover this change?
        on_fail: Update or create spec before proceeding
      - type: decision
        content: What is the spec status?
        options:
          - Spec exists and matches -> Derive task, proceed
          - Spec exists but outdated -> Update spec first
          - No spec exists -> Create spec first (behavior) or task directly (infra)
      - type: action
        content: Update or create spec item if needed
      - type: action
        content: Derive task from spec via kspec derive @spec-item
      - type: action
        content: Implement the change
  - _ulid: 01KH53W0D7GT6C50PGEP07SPEV
    id: create-workflow
    trigger: manual
    description: Meta-workflow for creating new workflows. Ensures consistent structure and matching
      skill integration.
    steps:
      - type: action
        content: |-
          Identify the pattern to formalize.
          What process/checklist are you capturing? Where is it documented?
          Look for: step-by-step instructions, checklists, repeated sequences.
      - type: action
        content: |-
          Define the trigger - when does this workflow start?
          Common triggers: manual, session-start, session-end, task-complete,
          behavior-change, pre-release, pr-merge
      - type: action
        content: |-
          Design the steps. For each step decide:
          - Type: action (do something), check (verify condition), decision (choose path)
          - Content: clear instruction, can be multiline
          - For checks: on_fail message
          - For decisions: options list
      - type: action
        content: |-
          Create the workflow:
          kspec meta add workflow --id <id> --trigger <trigger> --description "..." --steps "[...]"
      - type: decision
        content: Does this workflow need a matching skill for additional context?
        options:
          - Yes - create/update skill in .claude/skills/<name>/SKILL.md
          - No - workflow is self-contained or context exists elsewhere
      - type: action
        content: |-
          Test the workflow:
          kspec workflow start @workflow-id
          Run through each step with workflow next
          Verify inputs/notes are captured correctly
      - type: check
        content: Commit changes to both main (skill) and shadow (workflow) branches
  - _ulid: 01KH53WBNQFWW4PVZEQTPSSM67
    id: session-reflect-loop
    trigger: loop-iteration-end
    description: Autonomous reflection for loop mode. High-confidence captures only. MUST search
      existing before capturing. No user interaction.
    steps:
      - type: action
        content: |-
          MANDATORY FIRST STEP: Search existing state before identifying anything.
          Run these searches in parallel:
          - kspec meta observations list
          - kspec inbox list
          - kspec tasks list

          This establishes baseline to prevent duplicates.
      - type: action
        content: |-
          Identify high-confidence friction points and successes.

          HIGH CONFIDENCE criteria:
          - Concrete and specific (not vague)
          - Systemic/repeatable (not one-off)
          - Clear cause and effect
          - Agent has certainty about the pattern

          LOW CONFIDENCE (DO NOT capture):
          - Vague observations
          - Uncertain patterns
          - One-off issues
          - Hypothetical problems

          For each item identified, check against search results from step 1.
      - type: decision
        content: |-
          For each potential item, evaluate against existing state:

          If matches existing observation/inbox/task -> SKIP IT, note existing ref
          If unique AND high-confidence -> CAPTURE IT
          If vague/uncertain -> SKIP IT
      - type: action
        content: |-
          Capture approved items automatically (no user prompt):

          - Systemic friction: kspec meta observe friction "..."
          - Successful patterns: kspec meta observe success "..."
          - Open questions: kspec meta question add "..."
          - Actionable improvements with scope: kspec inbox add "..." --tag reflection

          Only capture items that passed the evaluation in step 3.
          Be selective - lower volume, higher quality.
  - _ulid: 01KH53X8R9V2QX5FKMZYMA5ABV
    id: task-work-loop
    trigger: manual
    description: "Loop variant of task-work-session for autonomous agents. Auto-filters to
      automation-eligible tasks, auto-resolves decisions. Task selection: in_progress > unblocking >
      priority. Still verifies work needed. PR review handled externally by ralph."
    steps:
      - type: action
        content: |-
          Filter to automation-eligible tasks only.
          Use: kspec tasks ready --eligible
          This ensures only tasks marked automation: eligible are considered.
        execution:
          mode: silent
      - type: decision
        content: |-
          Select task by priority order.
          First, run kspec tasks ready --eligible — its output is authoritative.
          Check in order:
          1. in_progress tasks (continue existing work)
          2. Ready tasks that unblock others (high impact)
          3. Highest priority ready task (lowest number = higher priority)

          Note: pending_review tasks are handled externally by ralph spawning PR review subagents.
        options:
          - in_progress task exists -> continue that task
          - Ready task unblocks others -> select that task
          - Only isolated ready tasks -> select highest priority (lowest number)
          - kspec tasks ready --eligible returned empty -> stop responding (ralph exits
            automatically)
          - kspec tasks ready --eligible shows all blocked -> stop responding (ralph exits
            automatically)
        execution:
          mode: silent
      - type: check
        content: |-
          Verify work is needed - but VALIDATE, do not trust notes.

          Notes are context, not proof. If a task is in the queue, there is a reason.

          To mark Already implemented you MUST:
          1. RUN the tests - they must PASS, not skip
          2. VERIFY AC coverage - each AC has a corresponding test
          3. CHECK implementation matches spec requirements

          DO NOT mark complete just because:
          - Notes say already done (verify yourself)
          - Tests exist but skip in CI (that is a gap to fix)
          - Someone said it was implemented (run the tests)
        on_fail: |-
          Only if tests PASS and ACs are COVERED:
          Mark task complete with Already implemented reason and EXIT
        execution:
          mode: silent
      - type: action
        content: |-
          Start selected task (if not already in_progress).
          Use: kspec task start @task
        execution:
          mode: silent
      - type: action
        content: |-
          Work on the task, adding notes as you go.
          Use: kspec task note @task "What you are doing..."
          Add notes during work, not just at end.

          SCOPE EXPANSION: If you discover missing implementation while testing,
          implementing it IS in scope. The goal is verified behavior, not just test files.
          Add tests for X means ensure X is verified - if X does not exist, implement it.
      - type: check
        content: |-
          Verify Definition of Done before committing.

          Read task notes for any DoD criteria. Common constraints:
          - No test.skip() calls - verify no skipped tests in changes
          - All ACs covered - verify each AC has corresponding test
          - No TODO/FIXME - no placeholder comments

          If DoD criteria exist and are not met, fix the gaps first.
        on_fail: |-
          Do not proceed with DoD violations.
          Either fix the gaps or escalate to user if scope is unclear.
        execution:
          mode: silent
      - type: action
        content: |-
          Commit changes with Task: @task trailer.
          All changes must be committed before submitting.
        execution:
          mode: silent
      - type: action
        content: |-
          Submit task for review.
          Use: kspec task submit @task
          This marks the task pending_review.
        execution:
          mode: silent
      - type: action
        content: |-
          Create PR.
          Use: /pr skill
          After PR created, EXIT - ralph handles PR review via separate subagent.
        execution:
          mode: silent
conventions:
  - _ulid: 01KH4D4XBHYX71V8BQF8NVQTA1
    domain: commits
    rules:
      - Use conventional commit format (feat, fix, docs, refactor, test, chore)
      - Include Task trailer when completing task work
      - Include Spec trailer when implementing spec item
      - Keep subject line under 72 characters
    examples: []
  - _ulid: 01KH4D54RSWVY7TE2E8RBV892W
    domain: notes
    rules:
      - Add notes during work, not just at end
      - Include context for decisions made
      - Reference related commits, PRs, or issues
    examples: []
  - _ulid: 01KH509WYHJKSQ1XXE7FYDATA1
    domain: testing
    rules:
      - Every implementation task must include tests covering its spec ACs
      - "Tests must be annotated with # AC: @spec-ref ac-N comments linking to the spec AC they
        cover"
      - The local-review workflow checks for AC annotation coverage before PR
      - Tests must not require a running ComfyUI instance or GPU
    examples: []
observations:
  - _ulid: 01KH5140KRDP91DHZCZ3Z2G0XZ
    type: success
    content: "Parallel subagent research during spec-plan-design: Launching a general-purpose subagent
      for ComfyUI testing research while continuing main conversation was efficient and produced
      comprehensive findings without blocking the planning flow."
    created_at: 2026-02-11T00:20:20.216Z
    author: "@claude"
    resolved: false
    resolution: null
  - _ulid: 01KH5142AKZ0J43JTZ4PZ8BPXY
    type: success
    content: "kspec batch for bulk operations: Using atomic batch to mark 21 tasks eligible and wire 18
      dependency links saved significant time. Atomic rollback on typo was correct behavior and
      caught the error cleanly."
    created_at: 2026-02-11T00:20:21.971Z
    author: "@claude"
    resolved: false
    resolution: null
  - _ulid: 01KH5HAKP98WMBZXARWR21BD4N
    type: friction
    content: "pytest vs ComfyUI __init__.py: Root __init__.py with relative imports (from .nodes.x)
      breaks pytest Package collector. Fix requires three-part solution: (1) try/except ImportError
      in __init__.py, (2) collect_ignore = ['__init__.py'] in root conftest.py, (3)
      --import-mode=importlib in pytest config. Took 6 iterations to discover this pattern."
    created_at: 2026-02-11T05:03:33.577Z
    author: "@claude"
    resolved: true
    resolution: "Resolved by PR #29: relative imports + _UnifiedFinder conftest.py. 491 tests pass, 0
      deprecation warnings, ComfyUI loads correctly."
    resolved_at: 2026-02-11T17:12:25.427Z
    resolved_by: "@claude"
  - _ulid: 01KH6V1DD255YA5H8QMGBHDP4B
    type: success
    content: "Detailed handoff documents with root cause analysis: The fix/relative-imports handoff
      correctly identified the dual module identity problem, listed option space (A/B/C), and
      pinpointed the broken _SubpackageFinder in conftest.py. This saved significant debugging time
      on a complex Python import system issue. Pattern: when handing off complex debugging tasks,
      include specific root cause hypothesis and concrete file-level pointers."
    created_at: 2026-02-11T17:12:32.418Z
    author: "@claude"
    resolved: false
    resolution: null
  - _ulid: 01KH6Y5YY3XCP36WXH9PZ2TK88
    type: success
    content: Parallel codex + claude review on the same PR catches issues from different angles and
      builds confidence in diagnosis. Codex found the same key prefix bug independently.
    created_at: 2026-02-11T18:07:27.171Z
    author: "@claude"
    resolved: false
    resolution: null
  - _ulid: 01KH6Y61A4GBSDFYSKK5HRX26R
    type: friction
    content: Unit tests with mocks can validate the wrong behavior when the mock reproduces a production
      bug. Key prefix mismatch was invisible because MockModelPatcher had the same inconsistency as
      real code. Live runtime testing was the only way to catch it.
    created_at: 2026-02-11T18:07:29.604Z
    author: "@claude"
    resolved: false
    resolution: null
  - _ulid: 01KH71QQWF7YPS5BVN3MNKB401
    type: success
    content: "Reference implementation comparison is highly effective for debugging correctness issues.
      When output is wrong, diff the code path against the known-good reference (merge-router) step
      by step — traces through real framework code (ComfyUI calculate_weight) rather than mocks.
      Found two bugs in one session this way: tuple format and alpha reading."
    created_at: 2026-02-11T19:09:35.503Z
    author: "@claude"
    resolved: false
    resolution: null
  - _ulid: 01KH7F8SGESVV3N6CK38EPRRFV
    type: friction
    content: "Ported grouping criteria not verified against downstream consumers: OpSignature included
      affecting_sets (from merge-router port) but the evaluation pipeline never consumed it — the
      loader already filters by set_id. This caused 200+ tiny groups instead of ~10. Pattern: when
      porting algorithms, trace each grouping/filtering criterion through the full pipeline to
      verify it is actually used, not just structurally mirrored from the source."
    created_at: 2026-02-11T23:06:05.710Z
    author: "@claude"
    resolved: false
    resolution: null
  - _ulid: 01KH7MPS72Z8R7PBZJZ1DECGJ9
    type: friction
    content: Tasks can get stuck in pending_review between sessions when PR merges but task complete is
      never called. Session start should check for pending_review tasks and prompt completion.
    created_at: 2026-02-12T00:41:07.042Z
    author: "@claude"
    resolved: false
    resolution: null
  - _ulid: 01KH7MQ085CVEG86MGGV082JT3
    type: success
    content: Parallel subagent evaluation of all pending tasks against codebase state — quickly
      identified 2 already-complete, 2 partial, and 6 genuinely pending tasks in one pass
    created_at: 2026-02-12T00:41:14.245Z
    author: "@claude"
    resolved: false
    resolution: null
  - _ulid: 01KH89KAN9WEDS2WSA6R37NS9M
    type: success
    content: "Parallel 3-agent research pattern for audit tasks: launch mock-impl, real-API, and
      usage-pattern agents simultaneously. One round produced comprehensive audit with no follow-up
      needed. Good for any comparison/divergence analysis."
    created_at: 2026-02-12T06:46:13.929Z
    author: "@claude"
    resolved: false
    resolution: null
  - _ulid: 01KH8CFD570MKM3SG96WSX33W1
    type: success
    content: Explore subagent (very thorough) for multi-module context gathering — one round-trip to
      build comprehensive mental model spanning batch_groups, recipe_eval, gpu_ops, and test
      patterns. Saved many sequential reads on the E2E multi-set task.
    created_at: 2026-02-12T07:36:31.143Z
    author: "@claude"
    resolved: false
    resolution: null
  - _ulid: 01KH9NXRHCM2E593FM3PPZX5ND
    type: success
    content: "Parallel 4-agent deep dive for performance analysis: GPU ops, recipe walking, merge-router
      comparison, LoRA loading. Produced comprehensive view in ~90s. Interactive triage with
      AskUserQuestion per item (create/research/inbox/skip) kept user aligned and prevented 3 wasted
      tasks through research-before-acting."
    created_at: 2026-02-12T19:40:53.165Z
    author: "@claude"
    resolved: false
    resolution: null
  - _ulid: 01KH9NXZRX3PEXBXCRE60K11V7
    type: friction
    content: Subagent research quality unreliable for quantitative claims - ranking agent said <0.5% of
      merge time, background benchmark said 48.7%, correct benchmark with realistic shapes showed
      1.9% on GPU. Three different numbers, only the manual benchmark was right. Need to validate
      perf claims with real measurements.
    created_at: 2026-02-12T19:41:00.573Z
    author: "@claude"
    resolved: false
    resolution: null
  - _ulid: 01KH9YAW290Y1NJBEWD428TQCZ
    type: success
    content: "Parallel codex + pr-review catches complementary issues: codex found VRAM regression
      (register liveness), pr-review caught style/annotation gaps. Both completed in ~3min."
    created_at: 2026-02-12T22:07:51.369Z
    author: "@claude"
    resolved: false
    resolution: null
includes: []
