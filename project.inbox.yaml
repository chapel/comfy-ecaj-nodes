inbox:
  - _ulid: 01KH6X7H11QMP6A1ZZ0NFJQGKC
    text: "WIDEN Exit node produces corrupted model output when executing the GPU merge pipeline. Nodes
      now execute (key prefix mismatch fixed) but the merged weights are wrong. Need to debug:
      evaluate_recipe data flow, WIDEN filter/merge math with real z-image tensors,
      install_merged_patches correctness, and possible dtype/device mismatches. Test with actual
      ComfyUI runtime."
    created_at: 2026-02-11T17:50:49.889Z
    tags:
      - correctness
      - runtime
    added_by: "@claude"
  - _ulid: 01KH6Y5JPJ1G6FEHKBMV3N1YV4
    text: Audit MockModelPatcher for mock/production divergences. The key prefix mismatch bug
      (model_state_dict prefixed vs model.diffusion_model.state_dict unprefixed) was invisible to
      tests because the mock faithfully reproduced the same inconsistency. Review all
      MockModelPatcher API surfaces against real ComfyUI ModelPatcher behavior to catch similar
      hidden mismatches.
    created_at: 2026-02-11T18:07:14.642Z
    tags:
      - testing
      - review-finding
    added_by: "@claude"
  - _ulid: 01KH70DTFFBGDSWG2X09CQ733V
    text: "Performance: batched GPU pipeline is ~2-3x slower than merge-router reference. Key
      bottlenecks: (1) Excessive gc.collect()+empty_cache() after every chunk AND every OpSig group
      — reference only cleans between stages (~60 vs ~30 cleanups). Files: gpu_ops.py:292-294,
      exit.py:400-404. (2) No block-level pre-grouping — we compile OpSig groups across ALL keys
      creating ~200+ tiny groups vs reference's ~50 via block pre-grouping. Files: exit.py:343-348,
      batch_groups.py:33-66. (3) Linear O(N) search in apply_lora_batch_gpu to find matching spec
      after delta computation. Files: gpu_ops.py:205,224. (4) No pin_memory for async CPU→GPU
      transfers. Priority order: remove per-chunk cleanup (30-40% win), pre-group by block (4x fewer
      groups), pre-build index dict, add pin_memory."
    created_at: 2026-02-11T18:46:41.903Z
    tags:
      - performance
      - gpu
    added_by: "@claude"
